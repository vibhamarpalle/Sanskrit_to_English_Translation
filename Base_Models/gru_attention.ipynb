{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35479bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              English               Sanskrit\n",
      "0     <start> I <end>     <start> अहम् <end>\n",
      "1    <start> me <end>     <start> माम् <end>\n",
      "2   <start> you <end>    <start> त्वम् <end>\n",
      "3    <start> go <end>     <start> गच्छ <end>\n",
      "4  <start> went <end>  <start> अगच्छत् <end>\n",
      "Vocab size (Sanskrit): 1267\n",
      "Vocab size (English): 1138\n",
      "WARNING:tensorflow:From C:\\Users\\harsh\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, None, 512)            648704    ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " gru (GRU)                   [(None, None, 512),          1575936   ['embedding[0][0]']           \n",
      "                              (None, 512)]                                                        \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, None, 512)            582656    ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " gru_1 (GRU)                 [(None, None, 512),          1575936   ['embedding_1[0][0]',         \n",
      "                              (None, 512)]                           'gru[0][1]']                 \n",
      "                                                                                                  \n",
      " attention (Attention)       ((None, None, 512),          65729     ['gru[0][0]',                 \n",
      "                              (None, None, None, 1))                 'gru_1[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, None, 1024)           0         ['attention[0][0]',           \n",
      "                                                                     'gru_1[0][0]']               \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, None, 1138)           1166450   ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5615411 (21.42 MB)\n",
      "Trainable params: 5615411 (21.42 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/55\n",
      "WARNING:tensorflow:From C:\\Users\\harsh\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\harsh\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "21/21 [==============================] - 17s 338ms/step - loss: 3.2500 - accuracy: 0.6494 - val_loss: 1.4399 - val_accuracy: 0.8235\n",
      "Epoch 2/55\n",
      "21/21 [==============================] - 5s 239ms/step - loss: 1.3251 - accuracy: 0.8240 - val_loss: 1.4768 - val_accuracy: 0.8235\n",
      "Epoch 3/55\n",
      "21/21 [==============================] - 6s 283ms/step - loss: 1.2320 - accuracy: 0.8244 - val_loss: 1.5026 - val_accuracy: 0.8235\n",
      "Epoch 4/55\n",
      "21/21 [==============================] - 6s 271ms/step - loss: 1.2112 - accuracy: 0.8250 - val_loss: 1.5366 - val_accuracy: 0.8235\n",
      "Epoch 5/55\n",
      "21/21 [==============================] - 5s 229ms/step - loss: 1.1999 - accuracy: 0.8275 - val_loss: 1.5416 - val_accuracy: 0.8235\n",
      "Epoch 6/55\n",
      "21/21 [==============================] - 5s 231ms/step - loss: 1.1937 - accuracy: 0.8284 - val_loss: 1.5506 - val_accuracy: 0.8240\n",
      "Epoch 7/55\n",
      "21/21 [==============================] - 5s 228ms/step - loss: 1.1874 - accuracy: 0.8287 - val_loss: 1.5784 - val_accuracy: 0.8240\n",
      "Epoch 8/55\n",
      "21/21 [==============================] - 5s 232ms/step - loss: 1.1815 - accuracy: 0.8287 - val_loss: 1.5980 - val_accuracy: 0.8240\n",
      "Epoch 9/55\n",
      "21/21 [==============================] - 5s 227ms/step - loss: 1.1759 - accuracy: 0.8289 - val_loss: 1.6005 - val_accuracy: 0.8240\n",
      "Epoch 10/55\n",
      "21/21 [==============================] - 5s 229ms/step - loss: 1.1704 - accuracy: 0.8293 - val_loss: 1.6202 - val_accuracy: 0.8245\n",
      "Epoch 11/55\n",
      "21/21 [==============================] - 5s 228ms/step - loss: 1.1653 - accuracy: 0.8293 - val_loss: 1.6285 - val_accuracy: 0.8245\n",
      "Epoch 12/55\n",
      "21/21 [==============================] - 5s 227ms/step - loss: 1.1574 - accuracy: 0.8294 - val_loss: 1.6021 - val_accuracy: 0.8245\n",
      "Epoch 13/55\n",
      "21/21 [==============================] - 5s 230ms/step - loss: 1.1415 - accuracy: 0.8293 - val_loss: 1.5992 - val_accuracy: 0.8251\n",
      "Epoch 14/55\n",
      "21/21 [==============================] - 5s 233ms/step - loss: 1.1157 - accuracy: 0.8291 - val_loss: 1.5970 - val_accuracy: 0.8256\n",
      "Epoch 15/55\n",
      "21/21 [==============================] - 5s 233ms/step - loss: 1.0950 - accuracy: 0.8291 - val_loss: 1.6064 - val_accuracy: 0.8256\n",
      "Epoch 16/55\n",
      "21/21 [==============================] - 5s 236ms/step - loss: 1.0759 - accuracy: 0.8296 - val_loss: 1.6462 - val_accuracy: 0.8256\n",
      "Epoch 17/55\n",
      "21/21 [==============================] - 5s 231ms/step - loss: 1.0558 - accuracy: 0.8297 - val_loss: 1.6219 - val_accuracy: 0.8256\n",
      "Epoch 18/55\n",
      "21/21 [==============================] - 5s 235ms/step - loss: 1.0470 - accuracy: 0.8292 - val_loss: 1.6569 - val_accuracy: 0.8245\n",
      "Epoch 19/55\n",
      "21/21 [==============================] - 5s 234ms/step - loss: 1.0151 - accuracy: 0.8298 - val_loss: 1.7190 - val_accuracy: 0.8251\n",
      "Epoch 20/55\n",
      "21/21 [==============================] - 5s 238ms/step - loss: 0.9943 - accuracy: 0.8305 - val_loss: 1.7337 - val_accuracy: 0.8256\n",
      "Epoch 21/55\n",
      "21/21 [==============================] - 5s 228ms/step - loss: 0.9785 - accuracy: 0.8305 - val_loss: 1.7442 - val_accuracy: 0.8245\n",
      "Epoch 22/55\n",
      "21/21 [==============================] - 5s 230ms/step - loss: 0.9610 - accuracy: 0.8311 - val_loss: 1.7525 - val_accuracy: 0.8256\n",
      "Epoch 23/55\n",
      "21/21 [==============================] - 5s 229ms/step - loss: 0.9402 - accuracy: 0.8307 - val_loss: 1.7538 - val_accuracy: 0.8251\n",
      "Epoch 24/55\n",
      "21/21 [==============================] - 5s 231ms/step - loss: 0.9295 - accuracy: 0.8320 - val_loss: 1.7599 - val_accuracy: 0.8271\n",
      "Epoch 25/55\n",
      "21/21 [==============================] - 5s 231ms/step - loss: 0.9101 - accuracy: 0.8328 - val_loss: 1.7799 - val_accuracy: 0.8276\n",
      "Epoch 26/55\n",
      "21/21 [==============================] - 5s 230ms/step - loss: 0.8982 - accuracy: 0.8327 - val_loss: 1.7860 - val_accuracy: 0.8282\n",
      "Epoch 27/55\n",
      "21/21 [==============================] - 5s 233ms/step - loss: 0.8863 - accuracy: 0.8337 - val_loss: 1.8164 - val_accuracy: 0.8245\n",
      "Epoch 28/55\n",
      "21/21 [==============================] - 5s 240ms/step - loss: 0.8721 - accuracy: 0.8336 - val_loss: 1.7889 - val_accuracy: 0.8297\n",
      "Epoch 29/55\n",
      "21/21 [==============================] - 5s 261ms/step - loss: 0.8543 - accuracy: 0.8348 - val_loss: 1.8933 - val_accuracy: 0.8266\n",
      "Epoch 30/55\n",
      "21/21 [==============================] - 5s 249ms/step - loss: 0.8188 - accuracy: 0.8372 - val_loss: 1.8329 - val_accuracy: 0.8307\n",
      "Epoch 31/55\n",
      "21/21 [==============================] - 5s 241ms/step - loss: 0.7797 - accuracy: 0.8394 - val_loss: 1.9314 - val_accuracy: 0.8313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/55\n",
      "21/21 [==============================] - 5s 233ms/step - loss: 0.7473 - accuracy: 0.8443 - val_loss: 1.9420 - val_accuracy: 0.8328\n",
      "Epoch 33/55\n",
      "21/21 [==============================] - 5s 233ms/step - loss: 0.7197 - accuracy: 0.8445 - val_loss: 1.9019 - val_accuracy: 0.8339\n",
      "Epoch 34/55\n",
      "21/21 [==============================] - 5s 232ms/step - loss: 0.6969 - accuracy: 0.8489 - val_loss: 1.9537 - val_accuracy: 0.8370\n",
      "Epoch 35/55\n",
      "21/21 [==============================] - 5s 229ms/step - loss: 0.6765 - accuracy: 0.8502 - val_loss: 1.9831 - val_accuracy: 0.8359\n",
      "Epoch 36/55\n",
      "21/21 [==============================] - 5s 227ms/step - loss: 0.6535 - accuracy: 0.8570 - val_loss: 2.0145 - val_accuracy: 0.8385\n",
      "Epoch 37/55\n",
      "21/21 [==============================] - 5s 225ms/step - loss: 0.6352 - accuracy: 0.8604 - val_loss: 1.9829 - val_accuracy: 0.8406\n",
      "Epoch 38/55\n",
      "21/21 [==============================] - 5s 227ms/step - loss: 0.6117 - accuracy: 0.8644 - val_loss: 2.0420 - val_accuracy: 0.8390\n",
      "Epoch 39/55\n",
      "21/21 [==============================] - 5s 229ms/step - loss: 0.5866 - accuracy: 0.8701 - val_loss: 1.9740 - val_accuracy: 0.8401\n",
      "Epoch 40/55\n",
      "21/21 [==============================] - 5s 231ms/step - loss: 0.5832 - accuracy: 0.8711 - val_loss: 2.0343 - val_accuracy: 0.8390\n",
      "Epoch 41/55\n",
      "21/21 [==============================] - 5s 230ms/step - loss: 0.5754 - accuracy: 0.8733 - val_loss: 2.0251 - val_accuracy: 0.8452\n",
      "Epoch 42/55\n",
      "21/21 [==============================] - 5s 229ms/step - loss: 0.5500 - accuracy: 0.8779 - val_loss: 2.0693 - val_accuracy: 0.8416\n",
      "Epoch 43/55\n",
      "21/21 [==============================] - 5s 231ms/step - loss: 0.5170 - accuracy: 0.8812 - val_loss: 2.0839 - val_accuracy: 0.8468\n",
      "Epoch 44/55\n",
      "21/21 [==============================] - 5s 229ms/step - loss: 0.4871 - accuracy: 0.8869 - val_loss: 2.0797 - val_accuracy: 0.8458\n",
      "Epoch 45/55\n",
      "21/21 [==============================] - 5s 230ms/step - loss: 0.4627 - accuracy: 0.8855 - val_loss: 2.0571 - val_accuracy: 0.8468\n",
      "Epoch 46/55\n",
      "21/21 [==============================] - 5s 229ms/step - loss: 0.4427 - accuracy: 0.8899 - val_loss: 2.1225 - val_accuracy: 0.8483\n",
      "Epoch 47/55\n",
      "21/21 [==============================] - 5s 228ms/step - loss: 0.4244 - accuracy: 0.8924 - val_loss: 2.0762 - val_accuracy: 0.8483\n",
      "Epoch 48/55\n",
      "21/21 [==============================] - 5s 229ms/step - loss: 0.4159 - accuracy: 0.8958 - val_loss: 2.1547 - val_accuracy: 0.8473\n",
      "Epoch 49/55\n",
      "21/21 [==============================] - 5s 229ms/step - loss: 0.4110 - accuracy: 0.8947 - val_loss: 2.1719 - val_accuracy: 0.8509\n",
      "Epoch 50/55\n",
      "21/21 [==============================] - 5s 225ms/step - loss: 0.3948 - accuracy: 0.9007 - val_loss: 2.1276 - val_accuracy: 0.8509\n",
      "Epoch 51/55\n",
      "21/21 [==============================] - 5s 227ms/step - loss: 0.3821 - accuracy: 0.9009 - val_loss: 2.1683 - val_accuracy: 0.8499\n",
      "Epoch 52/55\n",
      "21/21 [==============================] - 5s 229ms/step - loss: 0.3629 - accuracy: 0.9034 - val_loss: 2.1663 - val_accuracy: 0.8514\n",
      "Epoch 53/55\n",
      "21/21 [==============================] - 5s 229ms/step - loss: 0.3519 - accuracy: 0.9075 - val_loss: 2.1783 - val_accuracy: 0.8535\n",
      "Epoch 54/55\n",
      "21/21 [==============================] - 5s 229ms/step - loss: 0.3453 - accuracy: 0.9039 - val_loss: 2.2127 - val_accuracy: 0.8509\n",
      "Epoch 55/55\n",
      "21/21 [==============================] - 5s 226ms/step - loss: 0.3420 - accuracy: 0.9092 - val_loss: 2.1327 - val_accuracy: 0.8551\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input, Embedding, GRU, Dense, Concatenate\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_excel(\"C:/Users/harsh/Desktop/dict.xlsx\")\n",
    "\n",
    "# Add <start> and <end> tokens to each sentence\n",
    "df['Sanskrit'] = df['Sanskrit'].apply(lambda x: f\"<start> {x} <end>\")\n",
    "df['English'] = df['English'].apply(lambda x: f\"<start> {x} <end>\")\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# Create and fit tokenizers for both Sanskrit and English\n",
    "tokenizer_sanskrit = Tokenizer(filters='')\n",
    "tokenizer_sanskrit.fit_on_texts(df['Sanskrit'])\n",
    "tokenizer_english = Tokenizer(filters='')\n",
    "tokenizer_english.fit_on_texts(df['English'])\n",
    "\n",
    "# print(tokenizer_sanskrit.word_index)\n",
    "# print(tokenizer_english.word_index)\n",
    "# Vocabulary sizes\n",
    "vocab_size_sanskrit = len(tokenizer_sanskrit.word_index) + 1\n",
    "vocab_size_english = len(tokenizer_english.word_index) + 1\n",
    "print(f\"Vocab size (Sanskrit): {vocab_size_sanskrit}\")\n",
    "print(f\"Vocab size (English): {vocab_size_english}\")\n",
    "\n",
    "# Convert sentences to sequences\n",
    "sanskrit_sequences = tokenizer_sanskrit.texts_to_sequences(df['Sanskrit'])\n",
    "english_sequences = tokenizer_english.texts_to_sequences(df['English'])\n",
    "\n",
    "# Pad sequences\n",
    "max_len = max(max(len(seq) for seq in sanskrit_sequences), max(len(seq) for seq in english_sequences))\n",
    "sanskrit_padded = pad_sequences(sanskrit_sequences, maxlen=max_len, padding='post')\n",
    "english_padded = pad_sequences(english_sequences, maxlen=max_len, padding='post')\n",
    "\n",
    "# Define input and target data for training\n",
    "english_input_padded = pad_sequences(english_sequences, maxlen=max_len + 1, padding='post')[:, :-1]\n",
    "english_target_padded = pad_sequences(english_sequences, maxlen=max_len + 1, padding='post')[:, 1:]\n",
    "\n",
    "# Define the Attention layer\n",
    "class Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, encoder_outputs, decoder_outputs):\n",
    "        decoder_outputs_expanded = tf.expand_dims(decoder_outputs, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(encoder_outputs) + self.W2(decoder_outputs_expanded)))\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * encoder_outputs\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector, attention_weights\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Attention, self).get_config()\n",
    "        config.update({'units': self.units})\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "# Define encoder-decoder model with Attention\n",
    "encoder_input = Input(shape=(None,))\n",
    "encoder_embedding = Embedding(input_dim=vocab_size_sanskrit, output_dim=512)(encoder_input)\n",
    "encoder_outputs, state_h = GRU(512, return_sequences=True, return_state=True)(encoder_embedding)\n",
    "\n",
    "decoder_input = Input(shape=(None,))\n",
    "decoder_embedding = Embedding(input_dim=vocab_size_english, output_dim=512)(decoder_input)\n",
    "decoder_outputs, _ = GRU(512, return_sequences=True, return_state=True)(decoder_embedding, initial_state=state_h)\n",
    "\n",
    "attention = Attention(units=64)\n",
    "context_vector, attention_weights = attention(encoder_outputs, decoder_outputs)\n",
    "decoder_concat_input = Concatenate(axis=-1)([context_vector, decoder_outputs])\n",
    "\n",
    "output = Dense(vocab_size_english, activation='softmax')(decoder_concat_input)\n",
    "model = tf.keras.Model([encoder_input, decoder_input], output)\n",
    "\n",
    "# Compile model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Train the model with a few more epochs\n",
    "history=model.fit([sanskrit_padded, english_input_padded], english_target_padded, epochs=55, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Save the model and tokenizers\n",
    "model.save(\"C:/Users/harsh/Downloads/sanskrit_to_english_model2.keras\")\n",
    "with open('C:/Users/harsh/Desktop/tokenizer_sanskrit.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer_sanskrit, f)\n",
    "with open('C:/Users/harsh/Desktop/tokenizer_english.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer_english, f)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc8d9d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Sanskrit: वयम् -> Predicted English word: republic\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Sanskrit: ते -> Predicted English word: run\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Sanskrit: एतत् -> Predicted English word: approach\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Sanskrit: तत् -> Predicted English word: wellness\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Sanskrit: कः -> Predicted English word: morning\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Sanskrit: किम् -> Predicted English word: advice\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Sanskrit: कुत्र -> Predicted English word: without\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Sanskrit: कदा -> Predicted English word: religion\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Sanskrit: किमर्थम् -> Predicted English word: why\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Sanskrit: कथम् -> Predicted English word: sorrow\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Sanskrit: कतमः -> Predicted English word: which\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Sanskrit: आगच्छ -> Predicted English word: clean\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Sanskrit: उपविश -> Predicted English word: sit\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Sanskrit: तिष्ठ -> Predicted English word: any\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Sanskrit: वद -> Predicted English word: speak\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "Sanskrit: शृणु -> Predicted English word: adopted son\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Sanskrit: अश -> Predicted English word: eat\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Sanskrit: पिब -> Predicted English word: drink\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Sanskrit: स्वप -> Predicted English word: sleep\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Sanskrit: चर -> Predicted English word: annual\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Define the Attention layer (kept as is)\n",
    "class Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, encoder_outputs, decoder_outputs):\n",
    "        decoder_outputs_expanded = tf.expand_dims(decoder_outputs, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(encoder_outputs) + self.W2(decoder_outputs_expanded)))\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * encoder_outputs\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector, attention_weights\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Attention, self).get_config()\n",
    "        config.update({'units': self.units})\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "# Load the model with custom Attention layer\n",
    "custom_objects = {\n",
    "    'Attention': Attention,\n",
    "}\n",
    "\n",
    "model = tf.keras.models.load_model(\"C:/Users/harsh/Downloads/sanskrit_to_english_model2.keras\", custom_objects=custom_objects)\n",
    "\n",
    "# Load the tokenizers\n",
    "with open(\"C:/Users/harsh/Desktop/tokenizer_sanskrit.pkl\", 'rb') as f:\n",
    "    tokenizer_sanskrit = pickle.load(f)\n",
    "\n",
    "with open(\"C:/Users/harsh/Desktop/tokenizer_english.pkl\", 'rb') as f:\n",
    "    tokenizer_english = pickle.load(f)\n",
    "\n",
    "# Preprocess input sentence\n",
    "def preprocess_sentence(sentence, tokenizer, max_len):\n",
    "    seq = tokenizer.texts_to_sequences([f\"<start> {sentence} <end>\"])\n",
    "    padded_seq = pad_sequences(seq, maxlen=max_len, padding='post')\n",
    "    return padded_seq\n",
    "\n",
    "# Decode the predicted sequence into English\n",
    "def decode_sequence(sequence, tokenizer):\n",
    "    reverse_word_index = dict(map(reversed, tokenizer.word_index.items()))\n",
    "    return ' '.join([reverse_word_index.get(i, '') for i in sequence if i > 0])\n",
    "\n",
    "# Generate an English translation for an input Sanskrit sequence\n",
    "def predict_sequence(input_seq, max_len_output):\n",
    "    start_token_index = tokenizer_english.word_index.get(\"<start>\")\n",
    "    end_token_index = tokenizer_english.word_index.get(\"<end>\")\n",
    "\n",
    "    decoder_input_seq = np.zeros((1, max_len_output))\n",
    "    decoder_input_seq[0, 0] = start_token_index\n",
    "\n",
    "    predicted_seq = []\n",
    "\n",
    "    for i in range(1, max_len_output):\n",
    "        predictions = model.predict([input_seq, decoder_input_seq])\n",
    "        predicted_token_index = np.argmax(predictions[0, i-1, :])\n",
    "        #print(f\"Predicted token at step {i}: {predicted_token_index}\")\n",
    "\n",
    "        if predicted_token_index == end_token_index:\n",
    "            break\n",
    "\n",
    "        predicted_seq.append(predicted_token_index)\n",
    "        decoder_input_seq[0, i] = predicted_token_index\n",
    "\n",
    "    return np.array(predicted_seq)\n",
    "\n",
    "# Define max length for input and output sequences\n",
    "max_len_input = max_len\n",
    "max_len_output = max_len\n",
    "\n",
    "# Example sentence for translation\n",
    "#sanskrit_sentence = \"अगच्छत्\" \n",
    "# sanskrit_sentence = \"वयम्\" # Replace with any Sanskrit sentence\n",
    "# input_seq = preprocess_sentence(sanskrit_sentence, tokenizer_sanskrit, max_len_input)\n",
    "\n",
    "# # Predict and decode the sequence\n",
    "# predicted_seq = predict_sequence(input_seq, max_len_output)\n",
    "# english_sentence = decode_sequence(predicted_seq, tokenizer_english)\n",
    "# print(\"Predicted English Sentence:\", english_sentence)\n",
    "#test_sentences = [\"अगच्छत्\", \"कृते\", \"सर्वत्र\"]\n",
    "test_sentences = [\n",
    "    \"वयम्\",\n",
    "    \"ते\",\n",
    "    \"एतत्\",\n",
    "    \"तत्\",\n",
    "    \"कः\",\n",
    "    \"किम्\",\n",
    "    \"कुत्र\",\n",
    "    \"कदा\",\n",
    "    \"किमर्थम्\",\n",
    "    \"कथम्\",\n",
    "    \"कतमः\",\n",
    "    \"आगच्छ\",\n",
    "    \"उपविश\",\n",
    "    \"तिष्ठ\",\n",
    "    \"वद\",\n",
    "    \"शृणु\",\n",
    "    \"अश\",\n",
    "    \"पिब\",\n",
    "    \"स्वप\",\n",
    "    \"चर\"\n",
    "]\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    input_seq = preprocess_sentence(sentence, tokenizer_sanskrit, max_len_input)\n",
    "    predicted_seq = predict_sequence(input_seq, max_len_output)\n",
    "    english_sentence = decode_sequence(predicted_seq, tokenizer_english)\n",
    "    print(f\"Sanskrit: {sentence} -> Predicted English word: {english_sentence}\")\n",
    "\n",
    "# Tokenized sequences\n",
    "# print(\"Sample Sanskrit Sequence:\", tokenizer_sanskrit.texts_to_sequences([\"अगच्छत्\"]))\n",
    "# print(\"Sample English Sequence:\", tokenizer_english.texts_to_sequences([\"<start> brother <end>\"]))\n",
    "# Display the mapping of tokens to words\n",
    "# print(tokenizer_sanskrit.word_index)\n",
    "# print(tokenizer_english.word_index)\n",
    "# print(\"Sanskrit Padded Shape:\", sanskrit_padded.shape)\n",
    "# print(\"English Input Padded Shape:\", english_input_padded.shape)\n",
    "# print(\"English Target Padded Shape:\", english_target_padded.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7ec5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
