{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9201763,"sourceType":"datasetVersion","datasetId":5563352}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-25T10:17:38.902421Z","iopub.execute_input":"2024-08-25T10:17:38.902713Z","iopub.status.idle":"2024-08-25T10:17:39.269404Z","shell.execute_reply.started":"2024-08-25T10:17:38.902679Z","shell.execute_reply":"2024-08-25T10:17:39.268530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfile_path = '/kaggle/input/word-level/dict.csv'\nfile_path2='/kaggle/input/word-level/output_file.csv'\ndf1 = pd.read_csv(file_path)\ndf2=pd.read_csv(file_path2)\n\ndf1['Sanskrit'] = df1['Sanskrit'].apply(lambda x: x.lower().strip())\ndf1['English'] = df1['English'].apply(lambda x: x.lower().strip())\n\ndf2['Sanskrit'] = df2['Sanskrit'].apply(lambda x: x.lower().strip())\ndf2['English'] = df2['English'].apply(lambda x: x.lower().strip())","metadata":{"execution":{"iopub.status.busy":"2024-08-25T10:17:39.271189Z","iopub.execute_input":"2024-08-25T10:17:39.271582Z","iopub.status.idle":"2024-08-25T10:17:39.881225Z","shell.execute_reply.started":"2024-08-25T10:17:39.271548Z","shell.execute_reply":"2024-08-25T10:17:39.880278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([df1[['Sanskrit', 'English']], df2[['Sanskrit', 'English']]], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T10:17:39.882795Z","iopub.execute_input":"2024-08-25T10:17:39.883437Z","iopub.status.idle":"2024-08-25T10:17:39.910270Z","shell.execute_reply.started":"2024-08-25T10:17:39.883389Z","shell.execute_reply":"2024-08-25T10:17:39.909135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-08-25T10:17:39.912989Z","iopub.execute_input":"2024-08-25T10:17:39.913678Z","iopub.status.idle":"2024-08-25T10:17:39.933536Z","shell.execute_reply.started":"2024-08-25T10:17:39.913625Z","shell.execute_reply":"2024-08-25T10:17:39.932460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import pandas as pd\n# from tensorflow.keras.preprocessing.text import Tokenizer\n# from tensorflow.keras.preprocessing.sequence import pad_sequences\n# import numpy as np\n\n# # Example DataFrame\n# # df = pd.DataFrame({\n# #     'Sanskrit': ['संस्कृत', 'धर्म', 'ज्ञान'],\n# #     'English': ['sanskrit', 'dharma', 'knowledge']\n# # })\n\n# # Tokenize characters\n# input_tokenizer = Tokenizer(char_level=True)\n# target_tokenizer = Tokenizer(char_level=True)\n\n# input_tokenizer.fit_on_texts(df['Sanskrit'])\n# target_tokenizer.fit_on_texts(df['English'])\n\n# input_sequences = input_tokenizer.texts_to_sequences(df['Sanskrit'])\n# target_sequences = target_tokenizer.texts_to_sequences(df['English'])\n\n# max_input_length = max(len(seq) for seq in input_sequences)\n# max_target_length = max(len(seq) for seq in target_sequences)\n\n# input_sequences = pad_sequences(input_sequences, maxlen=max_input_length, padding='post')\n# target_sequences = pad_sequences(target_sequences, maxlen=max_target_length, padding='post')\n\n# input_vocab_size = len(input_tokenizer.word_index) + 1\n# target_vocab_size = len(target_tokenizer.word_index) + 1","metadata":{"execution":{"iopub.status.busy":"2024-08-25T10:17:39.935105Z","iopub.execute_input":"2024-08-25T10:17:39.935507Z","iopub.status.idle":"2024-08-25T10:18:05.434963Z","shell.execute_reply.started":"2024-08-25T10:17:39.935462Z","shell.execute_reply":"2024-08-25T10:18:05.433933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install indic_transliteration","metadata":{"execution":{"iopub.status.busy":"2024-08-25T12:11:34.145804Z","iopub.execute_input":"2024-08-25T12:11:34.146565Z","iopub.status.idle":"2024-08-25T12:11:51.381436Z","shell.execute_reply.started":"2024-08-25T12:11:34.146527Z","shell.execute_reply":"2024-08-25T12:11:51.380280Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from indic_transliteration import sanscript\nfrom indic_transliteration.sanscript import transliterate\n\ndef transliterate_text(sanskrit_text):\n    transliterated_text = transliterate(sanskrit_text, sanscript.DEVANAGARI, sanscript.IAST)\n    return transliterated_text\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T12:11:55.594706Z","iopub.execute_input":"2024-08-25T12:11:55.595126Z","iopub.status.idle":"2024-08-25T12:11:55.924658Z","shell.execute_reply.started":"2024-08-25T12:11:55.595086Z","shell.execute_reply":"2024-08-25T12:11:55.923827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Transliterated_Sanskrit']=df['Sanskrit'].apply(transliterate_text)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T12:12:00.536484Z","iopub.execute_input":"2024-08-25T12:12:00.536886Z","iopub.status.idle":"2024-08-25T12:12:05.946573Z","shell.execute_reply.started":"2024-08-25T12:12:00.536849Z","shell.execute_reply":"2024-08-25T12:12:05.945620Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-08-25T12:12:07.535349Z","iopub.execute_input":"2024-08-25T12:12:07.535735Z","iopub.status.idle":"2024-08-25T12:12:07.549067Z","shell.execute_reply.started":"2024-08-25T12:12:07.535697Z","shell.execute_reply":"2024-08-25T12:12:07.548219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Embedding, Conv1D, LSTM, GRU, Dense, TimeDistributed, Dropout, Bidirectional\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport numpy as np\nimport pandas as pd\n\n# Hyperparameters\nembedding_dim = 128\nfilters = 64\nkernel_size = 3\nlstm_units = 256\ndropout_rate = 0.5\nmax_seq_length = 100  \nvocab_size_sanskrit = 256  \nvocab_size_english = 256  \n\ntransliterated_sanskrit_texts = df['Transliterated_Sanskrit'].values\nenglish_texts = df['English'].values\n\n# Build character-level tokenizer for transliterated Sanskrit and English\ndef build_char_tokenizer(texts):\n    tokenizer = Tokenizer(char_level=True, filters='')\n    tokenizer.fit_on_texts(texts)\n    return tokenizer\n\ntransliterated_sanskrit_tokenizer = build_char_tokenizer(transliterated_sanskrit_texts)\nenglish_tokenizer = build_char_tokenizer(english_texts)\n\n# Convert texts to sequences\ntransliterated_sanskrit_sequences = transliterated_sanskrit_tokenizer.texts_to_sequences(transliterated_sanskrit_texts)\nenglish_sequences = english_tokenizer.texts_to_sequences(english_texts)\n\n# Pad sequences\ntransliterated_sanskrit_padded = pad_sequences(transliterated_sanskrit_sequences, maxlen=max_seq_length, padding='post')\nenglish_padded = pad_sequences(english_sequences, maxlen=max_seq_length, padding='post')\n\n# Build the model\ninput_layer = Input(shape=(max_seq_length,))  # Adjust input shape for character-level encoding\n\n# Embedding layer\nembedding_layer = Embedding(input_dim=vocab_size_sanskrit, output_dim=embedding_dim)(input_layer)\n\n# CNN layer\ncnn_layer = Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', padding='same')(embedding_layer)\n\n# LSTM or GRU layer (you can choose either)\nlstm_layer = Bidirectional(LSTM(lstm_units, return_sequences=True))(cnn_layer)\n# gru_layer = Bidirectional(GRU(lstm_units, return_sequences=True))(cnn_layer)\n\n# Dense layer for output\noutput_layer = TimeDistributed(Dense(vocab_size_english, activation='softmax'))(lstm_layer)\n\n# Create and compile the model\nmodel = Model(inputs=input_layer, outputs=output_layer)\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Print the model summary\nmodel.summary()\n\n# Train the model\n# Convert target sequences to 3D array of shape (batch_size, sequence_length, 1)\nenglish_padded = np.expand_dims(english_padded, -1)\nmodel.fit(transliterated_sanskrit_padded, english_padded, batch_size=64, epochs=20, validation_split=0.2)\n\n# Save the model\n# model.save('transliterated_sanskrit_to_english_translation_model.h5')\n\n# Prediction\n# Assuming `new_transliterated_sanskrit_texts` is a list of new transliterated Sanskrit sentences for prediction\n# new_transliterated_sanskrit_sequences = transliterated_sanskrit_tokenizer.texts_to_sequences(new_transliterated_sanskrit_texts)\n# new_transliterated_sanskrit_padded = pad_sequences(new_transliterated_sanskrit_sequences, maxlen=max_seq_length, padding='post')\n# predictions = model.predict(new_transliterated_sanskrit_padded)\n\n# # Decode predictions to English characters\n# index_word_english = {v: k for k, v in english_tokenizer.word_index.items()}\n\n# for prediction in predictions:\n#     predicted_sequence = [index_word_english.get(i, '') for i in prediction.argmax(axis=1)]\n#     print(''.join(predicted_sequence))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T12:13:34.018074Z","iopub.execute_input":"2024-08-25T12:13:34.018482Z","iopub.status.idle":"2024-08-25T12:34:54.713368Z","shell.execute_reply.started":"2024-08-25T12:13:34.018444Z","shell.execute_reply":"2024-08-25T12:34:54.712033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('/kaggle/working/hybrid.h5')\n# model.fit([input_sequences, target_sequences], np.expand_dims(decoder_target_data, -1), batch_size=64, epochs=10, validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T11:39:58.368889Z","iopub.execute_input":"2024-08-25T11:39:58.369277Z","iopub.status.idle":"2024-08-25T11:39:58.457619Z","shell.execute_reply.started":"2024-08-25T11:39:58.369239Z","shell.execute_reply":"2024-08-25T11:39:58.456585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# New transliterated Sanskrit sentence\nnew_sanskrit_sentence = \"naama\"\n\n# Convert the new Sanskrit sentence to sequences using the tokenizer\nnew_transliterated_sanskrit_sequences = transliterated_sanskrit_tokenizer.texts_to_sequences([new_sanskrit_sentence])\n\n# Pad the sequence to match the input length of the model\nnew_transliterated_sanskrit_padded = pad_sequences(new_transliterated_sanskrit_sequences, maxlen=max_seq_length, padding='post')\n\n# Make predictions using the trained model\npredictions = model.predict(new_transliterated_sanskrit_padded)\n\n# Decode predictions to English characters\nindex_word_english = {v: k for k, v in english_tokenizer.word_index.items()}\n\n# Convert predictions to text\npredicted_sentence = ''.join([index_word_english.get(i, '') for i in predictions[0].argmax(axis=1)])\n\nprint(\"Predicted English translation:\")\nprint(predicted_sentence)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T12:36:19.724295Z","iopub.execute_input":"2024-08-25T12:36:19.724651Z","iopub.status.idle":"2024-08-25T12:36:19.796556Z","shell.execute_reply.started":"2024-08-25T12:36:19.724618Z","shell.execute_reply":"2024-08-25T12:36:19.795659Z"},"trusted":true},"execution_count":null,"outputs":[]}]}