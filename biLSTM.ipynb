{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.17.0\n",
            "  Obtaining dependency information for tensorflow==2.17.0 from https://files.pythonhosted.org/packages/ed/b6/62345568cd07de5d9254fcf64d7e44aacbb6abde11ea953b3cb320e58d19/tensorflow-2.17.0-cp311-cp311-win_amd64.whl.metadata\n",
            "  Downloading tensorflow-2.17.0-cp311-cp311-win_amd64.whl.metadata (3.2 kB)\n",
            "Collecting keras==3.4.1\n",
            "  Obtaining dependency information for keras==3.4.1 from https://files.pythonhosted.org/packages/46/43/03fa53f027e78af4a6bee3564d05cb34d9f5b924dc69c85f8ef5cb950ff1/keras-3.4.1-py3-none-any.whl.metadata\n",
            "  Downloading keras-3.4.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting scikit-learn==1.5.2\n",
            "  Obtaining dependency information for scikit-learn==1.5.2 from https://files.pythonhosted.org/packages/17/1c/ccdd103cfcc9435a18819856fbbe0c20b8fa60bfc3343580de4be13f0668/scikit_learn-1.5.2-cp311-cp311-win_amd64.whl.metadata\n",
            "  Downloading scikit_learn-1.5.2-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
            "Collecting tensorflow-intel==2.17.0 (from tensorflow==2.17.0)\n",
            "  Obtaining dependency information for tensorflow-intel==2.17.0 from https://files.pythonhosted.org/packages/66/03/5c447feceb72f5a38ac2aa79d306fa5b5772f982c2b480c1329c7e382900/tensorflow_intel-2.17.0-cp311-cp311-win_amd64.whl.metadata\n",
            "  Downloading tensorflow_intel-2.17.0-cp311-cp311-win_amd64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: absl-py in c:\\users\\dell\\anaconda3\\lib\\site-packages (from keras==3.4.1) (2.1.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\dell\\anaconda3\\lib\\site-packages (from keras==3.4.1) (1.24.3)\n",
            "Requirement already satisfied: rich in c:\\users\\dell\\anaconda3\\lib\\site-packages (from keras==3.4.1) (13.7.1)\n",
            "Requirement already satisfied: namex in c:\\users\\dell\\anaconda3\\lib\\site-packages (from keras==3.4.1) (0.0.7)\n",
            "Requirement already satisfied: h5py in c:\\users\\dell\\anaconda3\\lib\\site-packages (from keras==3.4.1) (3.10.0)\n",
            "Requirement already satisfied: optree in c:\\users\\dell\\anaconda3\\lib\\site-packages (from keras==3.4.1) (0.10.0)\n",
            "Requirement already satisfied: ml-dtypes in c:\\users\\dell\\anaconda3\\lib\\site-packages (from keras==3.4.1) (0.3.2)\n",
            "Requirement already satisfied: packaging in c:\\users\\dell\\anaconda3\\lib\\site-packages (from keras==3.4.1) (23.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scikit-learn==1.5.2) (1.11.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scikit-learn==1.5.2) (1.2.0)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn==1.5.2)\n",
            "  Obtaining dependency information for threadpoolctl>=3.1.0 from https://files.pythonhosted.org/packages/4b/2c/ffbf7a134b9ab11a67b0cf0726453cedd9c5043a4fe7a35d1cefa9a1bcfb/threadpoolctl-3.5.0-py3-none-any.whl.metadata\n",
            "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (1.6.3)\n",
            "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.17.0->tensorflow==2.17.0)\n",
            "  Obtaining dependency information for flatbuffers>=24.3.25 from https://files.pythonhosted.org/packages/41/f0/7e988a019bc54b2dbd0ad4182ef2d53488bb02e58694cd79d61369e85900/flatbuffers-24.3.25-py2.py3-none-any.whl.metadata\n",
            "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (4.23.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (2.31.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (68.0.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (1.60.0)\n",
            "Collecting tensorboard<2.18,>=2.17 (from tensorflow-intel==2.17.0->tensorflow==2.17.0)\n",
            "  Obtaining dependency information for tensorboard<2.18,>=2.17 from https://files.pythonhosted.org/packages/d4/41/dccba8c5f955bc35b6110ff78574e4e5c8226ad62f08e732096c3861309b/tensorboard-2.17.1-py3-none-any.whl.metadata\n",
            "  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow==2.17.0) (0.31.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from rich->keras==3.4.1) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from rich->keras==3.4.1) (2.15.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow==2.17.0) (0.38.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras==3.4.1) (0.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow==2.17.0) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow==2.17.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow==2.17.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow==2.17.0) (2023.7.22)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow==2.17.0) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow==2.17.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow==2.17.0) (2.2.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow==2.17.0) (2.1.1)\n",
            "Downloading tensorflow-2.17.0-cp311-cp311-win_amd64.whl (2.0 kB)\n",
            "Downloading keras-3.4.1-py3-none-any.whl (1.1 MB)\n",
            "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
            "   ------------- -------------------------- 0.4/1.1 MB 11.6 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 1.0/1.1 MB 10.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 1.1/1.1 MB 10.3 MB/s eta 0:00:00\n",
            "Downloading scikit_learn-1.5.2-cp311-cp311-win_amd64.whl (11.0 MB)\n",
            "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
            "   --- ------------------------------------ 0.8/11.0 MB 13.2 MB/s eta 0:00:01\n",
            "   ------ --------------------------------- 1.7/11.0 MB 15.2 MB/s eta 0:00:01\n",
            "   -------- ------------------------------- 2.4/11.0 MB 16.8 MB/s eta 0:00:01\n",
            "   ----------- ---------------------------- 3.1/11.0 MB 16.6 MB/s eta 0:00:01\n",
            "   --------------- ------------------------ 4.2/11.0 MB 18.1 MB/s eta 0:00:01\n",
            "   ------------------ --------------------- 5.2/11.0 MB 18.3 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 5.9/11.0 MB 18.0 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 7.0/11.0 MB 18.7 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 8.0/11.0 MB 20.5 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 9.1/11.0 MB 20.1 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 10.1/11.0 MB 20.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------  11.0/11.0 MB 21.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  11.0/11.0 MB 21.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 11.0/11.0 MB 18.2 MB/s eta 0:00:00\n",
            "Downloading tensorflow_intel-2.17.0-cp311-cp311-win_amd64.whl (385.0 MB)\n",
            "   ---------------------------------------- 0.0/385.0 MB ? eta -:--:--\n",
            "   ---------------------------------------- 1.2/385.0 MB 36.8 MB/s eta 0:00:11\n",
            "   ---------------------------------------- 2.2/385.0 MB 28.6 MB/s eta 0:00:14\n",
            "   ---------------------------------------- 3.9/385.0 MB 27.9 MB/s eta 0:00:14\n",
            "    --------------------------------------- 5.0/385.0 MB 29.1 MB/s eta 0:00:14\n",
            "    --------------------------------------- 6.4/385.0 MB 29.2 MB/s eta 0:00:13\n",
            "    --------------------------------------- 7.6/385.0 MB 26.8 MB/s eta 0:00:15\n",
            "    --------------------------------------- 8.7/385.0 MB 26.6 MB/s eta 0:00:15\n",
            "   - -------------------------------------- 10.3/385.0 MB 27.3 MB/s eta 0:00:14\n",
            "   - -------------------------------------- 11.4/385.0 MB 27.3 MB/s eta 0:00:14\n",
            "   - -------------------------------------- 12.5/385.0 MB 27.3 MB/s eta 0:00:14\n",
            "   - -------------------------------------- 13.6/385.0 MB 27.3 MB/s eta 0:00:14\n",
            "   - -------------------------------------- 14.8/385.0 MB 26.2 MB/s eta 0:00:15\n",
            "   - -------------------------------------- 16.1/385.0 MB 28.5 MB/s eta 0:00:13\n",
            "   - -------------------------------------- 17.4/385.0 MB 26.2 MB/s eta 0:00:15\n",
            "   - -------------------------------------- 18.9/385.0 MB 28.4 MB/s eta 0:00:13\n",
            "   -- ------------------------------------- 20.2/385.0 MB 27.3 MB/s eta 0:00:14\n",
            "   -- ------------------------------------- 21.6/385.0 MB 27.3 MB/s eta 0:00:14\n",
            "   -- ------------------------------------- 23.0/385.0 MB 27.3 MB/s eta 0:00:14\n",
            "   -- ------------------------------------- 24.1/385.0 MB 28.5 MB/s eta 0:00:13\n",
            "   -- ------------------------------------- 25.2/385.0 MB 26.2 MB/s eta 0:00:14\n",
            "   -- ------------------------------------- 26.9/385.0 MB 27.3 MB/s eta 0:00:14\n",
            "   -- ------------------------------------- 28.0/385.0 MB 27.3 MB/s eta 0:00:14\n",
            "   --- ------------------------------------ 29.4/385.0 MB 26.2 MB/s eta 0:00:14\n",
            "   --- ------------------------------------ 30.5/385.0 MB 28.4 MB/s eta 0:00:13\n",
            "   --- ------------------------------------ 31.7/385.0 MB 26.2 MB/s eta 0:00:14\n",
            "   --- ------------------------------------ 32.8/385.0 MB 28.5 MB/s eta 0:00:13\n",
            "   --- ------------------------------------ 33.9/385.0 MB 28.4 MB/s eta 0:00:13\n",
            "   --- ------------------------------------ 35.2/385.0 MB 27.3 MB/s eta 0:00:13\n",
            "   --- ------------------------------------ 36.5/385.0 MB 28.5 MB/s eta 0:00:13\n",
            "   --- ------------------------------------ 37.8/385.0 MB 27.3 MB/s eta 0:00:13\n",
            "   ---- ----------------------------------- 39.3/385.0 MB 27.3 MB/s eta 0:00:13\n",
            "   ---- ----------------------------------- 40.6/385.0 MB 27.3 MB/s eta 0:00:13\n",
            "   ---- ----------------------------------- 41.8/385.0 MB 28.4 MB/s eta 0:00:13\n",
            "   ---- ----------------------------------- 43.1/385.0 MB 27.3 MB/s eta 0:00:13\n",
            "   ---- ----------------------------------- 44.4/385.0 MB 27.3 MB/s eta 0:00:13\n",
            "   ---- ----------------------------------- 45.7/385.0 MB 27.3 MB/s eta 0:00:13\n",
            "   ---- ----------------------------------- 47.2/385.0 MB 28.5 MB/s eta 0:00:12\n",
            "   ----- ---------------------------------- 48.3/385.0 MB 27.3 MB/s eta 0:00:13\n",
            "   ----- ---------------------------------- 49.3/385.0 MB 27.3 MB/s eta 0:00:13\n",
            "   ----- ---------------------------------- 50.7/385.0 MB 27.3 MB/s eta 0:00:13\n",
            "   ----- ---------------------------------- 51.8/385.0 MB 28.5 MB/s eta 0:00:12\n",
            "   ----- ---------------------------------- 53.0/385.0 MB 27.3 MB/s eta 0:00:13\n",
            "   ----- ---------------------------------- 54.0/385.0 MB 27.3 MB/s eta 0:00:13\n",
            "   ----- ---------------------------------- 55.2/385.0 MB 28.5 MB/s eta 0:00:12\n",
            "   ----- ---------------------------------- 56.1/385.0 MB 27.3 MB/s eta 0:00:13\n",
            "   ----- ---------------------------------- 57.3/385.0 MB 26.2 MB/s eta 0:00:13\n",
            "   ------ --------------------------------- 58.6/385.0 MB 27.3 MB/s eta 0:00:12\n",
            "   ------ --------------------------------- 59.8/385.0 MB 27.3 MB/s eta 0:00:12\n",
            "   ------ --------------------------------- 60.9/385.0 MB 27.3 MB/s eta 0:00:12\n",
            "   ------ --------------------------------- 62.5/385.0 MB 26.2 MB/s eta 0:00:13\n",
            "   ------ --------------------------------- 63.7/385.0 MB 26.2 MB/s eta 0:00:13\n",
            "   ------ --------------------------------- 64.7/385.0 MB 26.2 MB/s eta 0:00:13\n",
            "   ------ --------------------------------- 66.0/385.0 MB 26.2 MB/s eta 0:00:13\n",
            "   ------ --------------------------------- 67.1/385.0 MB 26.2 MB/s eta 0:00:13\n",
            "   ------- -------------------------------- 68.6/385.0 MB 26.2 MB/s eta 0:00:13\n",
            "   ------- -------------------------------- 69.7/385.0 MB 25.2 MB/s eta 0:00:13\n",
            "   ------- -------------------------------- 70.9/385.0 MB 26.2 MB/s eta 0:00:12\n",
            "   ------- -------------------------------- 72.0/385.0 MB 26.2 MB/s eta 0:00:12\n",
            "   ------- -------------------------------- 73.0/385.0 MB 25.2 MB/s eta 0:00:13\n",
            "   ------- -------------------------------- 74.4/385.0 MB 26.2 MB/s eta 0:00:12\n",
            "   ------- -------------------------------- 75.5/385.0 MB 25.2 MB/s eta 0:00:13\n",
            "   ------- -------------------------------- 76.7/385.0 MB 27.3 MB/s eta 0:00:12\n",
            "   -------- ------------------------------- 77.7/385.0 MB 26.2 MB/s eta 0:00:12\n",
            "   -------- ------------------------------- 79.4/385.0 MB 27.3 MB/s eta 0:00:12\n",
            "   -------- ------------------------------- 80.4/385.0 MB 26.2 MB/s eta 0:00:12\n",
            "   -------- ------------------------------- 81.8/385.0 MB 26.2 MB/s eta 0:00:12\n",
            "   -------- ------------------------------- 82.9/385.0 MB 26.2 MB/s eta 0:00:12\n",
            "   -------- ------------------------------- 84.2/385.0 MB 26.2 MB/s eta 0:00:12\n",
            "   -------- ------------------------------- 85.5/385.0 MB 27.3 MB/s eta 0:00:11\n",
            "   --------- ------------------------------ 86.6/385.0 MB 26.2 MB/s eta 0:00:12\n",
            "   --------- ------------------------------ 87.7/385.0 MB 26.2 MB/s eta 0:00:12\n",
            "   --------- ------------------------------ 89.0/385.0 MB 27.3 MB/s eta 0:00:11\n",
            "   --------- ------------------------------ 90.1/385.0 MB 27.3 MB/s eta 0:00:11\n",
            "   --------- ------------------------------ 91.1/385.0 MB 27.3 MB/s eta 0:00:11\n",
            "   --------- ------------------------------ 92.1/385.0 MB 27.3 MB/s eta 0:00:11\n",
            "   --------- ------------------------------ 93.5/385.0 MB 27.3 MB/s eta 0:00:11\n",
            "   --------- ------------------------------ 94.8/385.0 MB 28.5 MB/s eta 0:00:11\n",
            "   --------- ------------------------------ 96.0/385.0 MB 26.2 MB/s eta 0:00:12\n",
            "   ---------- ----------------------------- 97.1/385.0 MB 27.3 MB/s eta 0:00:11\n",
            "   ---------- ----------------------------- 99.0/385.0 MB 27.3 MB/s eta 0:00:11\n",
            "   ---------- ---------------------------- 100.4/385.0 MB 27.3 MB/s eta 0:00:11\n",
            "   ---------- ---------------------------- 101.6/385.0 MB 26.2 MB/s eta 0:00:11\n",
            "   ---------- ---------------------------- 103.2/385.0 MB 27.3 MB/s eta 0:00:11\n",
            "   ---------- ---------------------------- 104.3/385.0 MB 26.2 MB/s eta 0:00:11\n",
            "   ---------- ---------------------------- 105.6/385.0 MB 26.2 MB/s eta 0:00:11\n",
            "   ---------- ---------------------------- 107.0/385.0 MB 27.3 MB/s eta 0:00:11\n",
            "   ---------- ---------------------------- 108.2/385.0 MB 27.3 MB/s eta 0:00:11\n",
            "   ----------- --------------------------- 109.4/385.0 MB 27.3 MB/s eta 0:00:11\n",
            "   ----------- --------------------------- 110.7/385.0 MB 27.3 MB/s eta 0:00:11\n",
            "   ----------- --------------------------- 111.7/385.0 MB 27.3 MB/s eta 0:00:11\n",
            "   ----------- --------------------------- 112.8/385.0 MB 27.3 MB/s eta 0:00:10\n",
            "   ----------- --------------------------- 113.9/385.0 MB 27.3 MB/s eta 0:00:10\n",
            "   ----------- --------------------------- 115.2/385.0 MB 27.3 MB/s eta 0:00:10\n",
            "   ----------- --------------------------- 116.2/385.0 MB 27.3 MB/s eta 0:00:10\n",
            "   ----------- --------------------------- 117.2/385.0 MB 26.2 MB/s eta 0:00:11\n",
            "   ------------ -------------------------- 118.7/385.0 MB 26.2 MB/s eta 0:00:11\n",
            "   ------------ -------------------------- 119.7/385.0 MB 26.2 MB/s eta 0:00:11\n",
            "   ------------ -------------------------- 120.9/385.0 MB 26.2 MB/s eta 0:00:11\n",
            "   ------------ -------------------------- 122.0/385.0 MB 26.2 MB/s eta 0:00:11\n",
            "   ------------ -------------------------- 122.9/385.0 MB 25.2 MB/s eta 0:00:11\n",
            "   ------------ -------------------------- 124.2/385.0 MB 26.2 MB/s eta 0:00:10\n",
            "   ------------ -------------------------- 125.1/385.0 MB 25.2 MB/s eta 0:00:11\n",
            "   ------------ -------------------------- 126.2/385.0 MB 25.1 MB/s eta 0:00:11\n",
            "   ------------ -------------------------- 127.6/385.0 MB 25.1 MB/s eta 0:00:11\n",
            "   ------------- ------------------------- 129.0/385.0 MB 25.2 MB/s eta 0:00:11\n",
            "   ------------- ------------------------- 130.3/385.0 MB 25.2 MB/s eta 0:00:11\n",
            "   ------------- ------------------------- 131.8/385.0 MB 25.2 MB/s eta 0:00:11\n",
            "   ------------- ------------------------- 133.1/385.0 MB 26.2 MB/s eta 0:00:10\n",
            "   ------------- ------------------------- 134.4/385.0 MB 27.3 MB/s eta 0:00:10\n",
            "   ------------- ------------------------- 135.8/385.0 MB 27.3 MB/s eta 0:00:10\n",
            "   ------------- ------------------------- 137.3/385.0 MB 27.3 MB/s eta 0:00:10\n",
            "   -------------- ------------------------ 138.5/385.0 MB 27.3 MB/s eta 0:00:10\n",
            "   -------------- ------------------------ 140.0/385.0 MB 27.3 MB/s eta 0:00:09\n",
            "   -------------- ------------------------ 141.4/385.0 MB 27.3 MB/s eta 0:00:09\n",
            "   -------------- ------------------------ 142.5/385.0 MB 27.3 MB/s eta 0:00:09\n",
            "   -------------- ------------------------ 143.6/385.0 MB 28.4 MB/s eta 0:00:09\n",
            "   -------------- ------------------------ 144.8/385.0 MB 28.4 MB/s eta 0:00:09\n",
            "   -------------- ------------------------ 145.9/385.0 MB 28.4 MB/s eta 0:00:09\n",
            "   -------------- ------------------------ 147.4/385.0 MB 27.3 MB/s eta 0:00:09\n",
            "   --------------- ----------------------- 148.6/385.0 MB 27.3 MB/s eta 0:00:09\n",
            "   --------------- ----------------------- 150.0/385.0 MB 27.3 MB/s eta 0:00:09\n",
            "   --------------- ----------------------- 151.4/385.0 MB 27.3 MB/s eta 0:00:09\n",
            "   --------------- ----------------------- 152.7/385.0 MB 28.4 MB/s eta 0:00:09\n",
            "   --------------- ----------------------- 154.1/385.0 MB 27.3 MB/s eta 0:00:09\n",
            "   --------------- ----------------------- 155.5/385.0 MB 27.3 MB/s eta 0:00:09\n",
            "   --------------- ----------------------- 156.8/385.0 MB 27.3 MB/s eta 0:00:09\n",
            "   ---------------- ---------------------- 158.1/385.0 MB 28.5 MB/s eta 0:00:08\n",
            "   ---------------- ---------------------- 159.3/385.0 MB 27.3 MB/s eta 0:00:09\n",
            "   ---------------- ---------------------- 160.5/385.0 MB 27.3 MB/s eta 0:00:09\n",
            "   ---------------- ---------------------- 162.1/385.0 MB 27.3 MB/s eta 0:00:09\n",
            "   ---------------- ---------------------- 163.5/385.0 MB 28.5 MB/s eta 0:00:08\n",
            "   ---------------- ---------------------- 164.9/385.0 MB 28.5 MB/s eta 0:00:08\n",
            "   ---------------- ---------------------- 166.3/385.0 MB 28.5 MB/s eta 0:00:08\n",
            "   ---------------- ---------------------- 167.8/385.0 MB 28.4 MB/s eta 0:00:08\n",
            "   ----------------- --------------------- 169.6/385.0 MB 29.7 MB/s eta 0:00:08\n",
            "   ----------------- --------------------- 170.9/385.0 MB 29.8 MB/s eta 0:00:08\n",
            "   ----------------- --------------------- 172.2/385.0 MB 29.8 MB/s eta 0:00:08\n",
            "   ----------------- --------------------- 173.6/385.0 MB 28.4 MB/s eta 0:00:08\n",
            "   ----------------- --------------------- 174.7/385.0 MB 27.3 MB/s eta 0:00:08\n",
            "   ----------------- --------------------- 175.9/385.0 MB 27.3 MB/s eta 0:00:08\n",
            "   ----------------- --------------------- 177.4/385.0 MB 27.3 MB/s eta 0:00:08\n",
            "   ----------------- --------------------- 177.6/385.0 MB 24.2 MB/s eta 0:00:09\n",
            "   ------------------ -------------------- 179.3/385.0 MB 26.2 MB/s eta 0:00:08\n",
            "   ------------------ -------------------- 180.3/385.0 MB 25.2 MB/s eta 0:00:09\n",
            "   ------------------ -------------------- 181.7/385.0 MB 25.2 MB/s eta 0:00:09\n",
            "   ------------------ -------------------- 183.0/385.0 MB 26.2 MB/s eta 0:00:08\n",
            "   ------------------ -------------------- 183.9/385.0 MB 25.2 MB/s eta 0:00:08\n",
            "   ------------------ -------------------- 184.7/385.0 MB 24.2 MB/s eta 0:00:09\n",
            "   ------------------ -------------------- 186.2/385.0 MB 24.3 MB/s eta 0:00:09\n",
            "   ------------------ -------------------- 187.1/385.0 MB 23.4 MB/s eta 0:00:09\n",
            "   ------------------- ------------------- 187.8/385.0 MB 26.2 MB/s eta 0:00:08\n",
            "   ------------------- ------------------- 188.0/385.0 MB 23.4 MB/s eta 0:00:09\n",
            "   ------------------- ------------------- 188.7/385.0 MB 21.9 MB/s eta 0:00:09\n",
            "   ------------------- ------------------- 189.4/385.0 MB 19.8 MB/s eta 0:00:10\n",
            "   ------------------- ------------------- 190.2/385.0 MB 19.8 MB/s eta 0:00:10\n",
            "   ------------------- ------------------- 191.2/385.0 MB 19.3 MB/s eta 0:00:11\n",
            "   ------------------- ------------------- 192.1/385.0 MB 18.7 MB/s eta 0:00:11\n",
            "   ------------------- ------------------- 193.0/385.0 MB 18.2 MB/s eta 0:00:11\n",
            "   ------------------- ------------------- 193.9/385.0 MB 17.7 MB/s eta 0:00:11\n",
            "   ------------------- ------------------- 194.7/385.0 MB 18.7 MB/s eta 0:00:11\n",
            "   ------------------- ------------------- 195.5/385.0 MB 18.2 MB/s eta 0:00:11\n",
            "   ------------------- ------------------- 196.7/385.0 MB 18.2 MB/s eta 0:00:11\n",
            "   -------------------- ------------------ 197.8/385.0 MB 18.7 MB/s eta 0:00:10\n",
            "   -------------------- ------------------ 199.0/385.0 MB 21.1 MB/s eta 0:00:09\n",
            "   -------------------- ------------------ 199.9/385.0 MB 22.5 MB/s eta 0:00:09\n",
            "   -------------------- ------------------ 199.9/385.0 MB 22.5 MB/s eta 0:00:09\n",
            "   -------------------- ------------------ 200.5/385.0 MB 19.3 MB/s eta 0:00:10\n",
            "   -------------------- ------------------ 201.1/385.0 MB 19.2 MB/s eta 0:00:10\n",
            "   -------------------- ------------------ 201.8/385.0 MB 18.2 MB/s eta 0:00:11\n",
            "   -------------------- ------------------ 202.8/385.0 MB 17.7 MB/s eta 0:00:11\n",
            "   -------------------- ------------------ 203.8/385.0 MB 18.2 MB/s eta 0:00:10\n",
            "   -------------------- ------------------ 204.8/385.0 MB 19.3 MB/s eta 0:00:10\n",
            "   -------------------- ------------------ 205.6/385.0 MB 18.2 MB/s eta 0:00:10\n",
            "   -------------------- ------------------ 206.7/385.0 MB 18.7 MB/s eta 0:00:10\n",
            "   --------------------- ----------------- 207.6/385.0 MB 18.7 MB/s eta 0:00:10\n",
            "   --------------------- ----------------- 208.9/385.0 MB 18.7 MB/s eta 0:00:10\n",
            "   --------------------- ----------------- 210.0/385.0 MB 19.3 MB/s eta 0:00:10\n",
            "   --------------------- ----------------- 211.1/385.0 MB 22.6 MB/s eta 0:00:08\n",
            "   --------------------- ----------------- 212.3/385.0 MB 24.2 MB/s eta 0:00:08\n",
            "   --------------------- ----------------- 213.2/385.0 MB 24.3 MB/s eta 0:00:08\n",
            "   --------------------- ----------------- 214.6/385.0 MB 26.2 MB/s eta 0:00:07\n",
            "   --------------------- ----------------- 215.5/385.0 MB 26.2 MB/s eta 0:00:07\n",
            "   --------------------- ----------------- 216.6/385.0 MB 25.2 MB/s eta 0:00:07\n",
            "   ---------------------- ---------------- 217.8/385.0 MB 27.3 MB/s eta 0:00:07\n",
            "   ---------------------- ---------------- 219.0/385.0 MB 27.3 MB/s eta 0:00:07\n",
            "   ---------------------- ---------------- 220.2/385.0 MB 25.2 MB/s eta 0:00:07\n",
            "   ---------------------- ---------------- 221.3/385.0 MB 26.2 MB/s eta 0:00:07\n",
            "   ---------------------- ---------------- 222.7/385.0 MB 25.2 MB/s eta 0:00:07\n",
            "   ---------------------- ---------------- 223.8/385.0 MB 25.1 MB/s eta 0:00:07\n",
            "   ---------------------- ---------------- 225.3/385.0 MB 25.2 MB/s eta 0:00:07\n",
            "   ---------------------- ---------------- 226.3/385.0 MB 25.2 MB/s eta 0:00:07\n",
            "   ---------------------- ---------------- 227.0/385.0 MB 26.2 MB/s eta 0:00:07\n",
            "   ----------------------- --------------- 227.3/385.0 MB 22.6 MB/s eta 0:00:07\n",
            "   ----------------------- --------------- 228.0/385.0 MB 21.9 MB/s eta 0:00:08\n",
            "   ----------------------- --------------- 229.3/385.0 MB 21.1 MB/s eta 0:00:08\n",
            "   ----------------------- --------------- 230.3/385.0 MB 21.8 MB/s eta 0:00:08\n",
            "   ----------------------- --------------- 231.4/385.0 MB 21.1 MB/s eta 0:00:08\n",
            "   ----------------------- --------------- 232.8/385.0 MB 22.6 MB/s eta 0:00:07\n",
            "   ----------------------- --------------- 233.6/385.0 MB 21.8 MB/s eta 0:00:07\n",
            "   ----------------------- --------------- 234.8/385.0 MB 21.1 MB/s eta 0:00:08\n",
            "   ----------------------- --------------- 235.8/385.0 MB 21.8 MB/s eta 0:00:07\n",
            "   ------------------------ -------------- 237.2/385.0 MB 21.1 MB/s eta 0:00:07\n",
            "   ------------------------ -------------- 238.1/385.0 MB 24.2 MB/s eta 0:00:07\n",
            "   ------------------------ -------------- 239.1/385.0 MB 24.2 MB/s eta 0:00:07\n",
            "   ------------------------ -------------- 240.3/385.0 MB 25.2 MB/s eta 0:00:06\n",
            "   ------------------------ -------------- 241.4/385.0 MB 25.2 MB/s eta 0:00:06\n",
            "   ------------------------ -------------- 242.8/385.0 MB 24.2 MB/s eta 0:00:06\n",
            "   ------------------------ -------------- 244.2/385.0 MB 25.1 MB/s eta 0:00:06\n",
            "   ------------------------ -------------- 245.0/385.0 MB 23.4 MB/s eta 0:00:06\n",
            "   ------------------------ -------------- 246.2/385.0 MB 24.2 MB/s eta 0:00:06\n",
            "   ------------------------- ------------- 247.4/385.0 MB 23.4 MB/s eta 0:00:06\n",
            "   ------------------------- ------------- 248.8/385.0 MB 24.2 MB/s eta 0:00:06\n",
            "   ------------------------- ------------- 250.2/385.0 MB 25.1 MB/s eta 0:00:06\n",
            "   ------------------------- ------------- 251.1/385.0 MB 24.2 MB/s eta 0:00:06\n",
            "   ------------------------- ------------- 252.1/385.0 MB 25.2 MB/s eta 0:00:06\n",
            "   ------------------------- ------------- 253.5/385.0 MB 24.2 MB/s eta 0:00:06\n",
            "   ------------------------- ------------- 254.6/385.0 MB 26.2 MB/s eta 0:00:05\n",
            "   ------------------------- ------------- 254.9/385.0 MB 25.2 MB/s eta 0:00:06\n",
            "   ------------------------- ------------- 255.1/385.0 MB 22.6 MB/s eta 0:00:06\n",
            "   ------------------------- ------------- 255.8/385.0 MB 21.8 MB/s eta 0:00:06\n",
            "   ------------------------- ------------- 256.3/385.0 MB 20.5 MB/s eta 0:00:07\n",
            "   -------------------------- ------------ 257.0/385.0 MB 19.9 MB/s eta 0:00:07\n",
            "   -------------------------- ------------ 258.4/385.0 MB 19.9 MB/s eta 0:00:07\n",
            "   -------------------------- ------------ 259.3/385.0 MB 19.8 MB/s eta 0:00:07\n",
            "   -------------------------- ------------ 260.5/385.0 MB 19.3 MB/s eta 0:00:07\n",
            "   -------------------------- ------------ 261.7/385.0 MB 19.8 MB/s eta 0:00:07\n",
            "   -------------------------- ------------ 262.7/385.0 MB 19.2 MB/s eta 0:00:07\n",
            "   -------------------------- ------------ 263.9/385.0 MB 19.2 MB/s eta 0:00:07\n",
            "   -------------------------- ------------ 265.2/385.0 MB 21.9 MB/s eta 0:00:06\n",
            "   -------------------------- ------------ 266.4/385.0 MB 24.2 MB/s eta 0:00:05\n",
            "   --------------------------- ----------- 267.6/385.0 MB 25.2 MB/s eta 0:00:05\n",
            "   --------------------------- ----------- 269.0/385.0 MB 25.1 MB/s eta 0:00:05\n",
            "   --------------------------- ----------- 269.6/385.0 MB 25.2 MB/s eta 0:00:05\n",
            "   --------------------------- ----------- 270.5/385.0 MB 24.2 MB/s eta 0:00:05\n",
            "   --------------------------- ----------- 271.5/385.0 MB 24.2 MB/s eta 0:00:05\n",
            "   --------------------------- ----------- 272.6/385.0 MB 24.2 MB/s eta 0:00:05\n",
            "   --------------------------- ----------- 273.4/385.0 MB 23.4 MB/s eta 0:00:05\n",
            "   --------------------------- ----------- 274.6/385.0 MB 23.4 MB/s eta 0:00:05\n",
            "   --------------------------- ----------- 275.6/385.0 MB 22.5 MB/s eta 0:00:05\n",
            "   ---------------------------- ---------- 276.9/385.0 MB 23.4 MB/s eta 0:00:05\n",
            "   ---------------------------- ---------- 278.3/385.0 MB 23.4 MB/s eta 0:00:05\n",
            "   ---------------------------- ---------- 279.4/385.0 MB 23.4 MB/s eta 0:00:05\n",
            "   ---------------------------- ---------- 279.6/385.0 MB 23.4 MB/s eta 0:00:05\n",
            "   ---------------------------- ---------- 280.0/385.0 MB 21.1 MB/s eta 0:00:05\n",
            "   ---------------------------- ---------- 280.1/385.0 MB 19.9 MB/s eta 0:00:06\n",
            "   ---------------------------- ---------- 280.6/385.0 MB 19.3 MB/s eta 0:00:06\n",
            "   ---------------------------- ---------- 281.5/385.0 MB 18.7 MB/s eta 0:00:06\n",
            "   ---------------------------- ---------- 282.4/385.0 MB 18.2 MB/s eta 0:00:06\n",
            "   ---------------------------- ---------- 283.8/385.0 MB 18.7 MB/s eta 0:00:06\n",
            "   ---------------------------- ---------- 284.7/385.0 MB 18.2 MB/s eta 0:00:06\n",
            "   ---------------------------- ---------- 285.9/385.0 MB 18.2 MB/s eta 0:00:06\n",
            "   ----------------------------- --------- 287.2/385.0 MB 18.2 MB/s eta 0:00:06\n",
            "   ----------------------------- --------- 288.6/385.0 MB 18.2 MB/s eta 0:00:06\n",
            "   ----------------------------- --------- 289.6/385.0 MB 18.7 MB/s eta 0:00:06\n",
            "   ----------------------------- --------- 290.7/385.0 MB 22.5 MB/s eta 0:00:05\n",
            "   ----------------------------- --------- 291.8/385.0 MB 23.4 MB/s eta 0:00:04\n",
            "   ----------------------------- --------- 292.6/385.0 MB 24.2 MB/s eta 0:00:04\n",
            "   ----------------------------- --------- 294.0/385.0 MB 24.2 MB/s eta 0:00:04\n",
            "   ----------------------------- --------- 294.9/385.0 MB 25.2 MB/s eta 0:00:04\n",
            "   ----------------------------- --------- 296.0/385.0 MB 24.2 MB/s eta 0:00:04\n",
            "   ------------------------------ -------- 297.0/385.0 MB 24.2 MB/s eta 0:00:04\n",
            "   ------------------------------ -------- 298.1/385.0 MB 24.3 MB/s eta 0:00:04\n",
            "   ------------------------------ -------- 298.8/385.0 MB 23.4 MB/s eta 0:00:04\n",
            "   ------------------------------ -------- 299.8/385.0 MB 23.4 MB/s eta 0:00:04\n",
            "   ------------------------------ -------- 300.9/385.0 MB 24.3 MB/s eta 0:00:04\n",
            "   ------------------------------ -------- 301.8/385.0 MB 23.4 MB/s eta 0:00:04\n",
            "   ------------------------------ -------- 302.9/385.0 MB 23.4 MB/s eta 0:00:04\n",
            "   ------------------------------ -------- 303.9/385.0 MB 23.4 MB/s eta 0:00:04\n",
            "   ------------------------------ -------- 304.8/385.0 MB 23.4 MB/s eta 0:00:04\n",
            "   ------------------------------ -------- 305.8/385.0 MB 23.4 MB/s eta 0:00:04\n",
            "   ------------------------------- ------- 306.4/385.0 MB 22.6 MB/s eta 0:00:04\n",
            "   ------------------------------- ------- 306.4/385.0 MB 22.6 MB/s eta 0:00:04\n",
            "   ------------------------------- ------- 307.5/385.0 MB 20.5 MB/s eta 0:00:04\n",
            "   ------------------------------- ------- 308.7/385.0 MB 21.1 MB/s eta 0:00:04\n",
            "   ------------------------------- ------- 309.8/385.0 MB 21.1 MB/s eta 0:00:04\n",
            "   ------------------------------- ------- 310.9/385.0 MB 21.1 MB/s eta 0:00:04\n",
            "   ------------------------------- ------- 312.0/385.0 MB 21.1 MB/s eta 0:00:04\n",
            "   ------------------------------- ------- 313.2/385.0 MB 21.1 MB/s eta 0:00:04\n",
            "   ------------------------------- ------- 314.1/385.0 MB 21.1 MB/s eta 0:00:04\n",
            "   ------------------------------- ------- 315.1/385.0 MB 21.1 MB/s eta 0:00:04\n",
            "   -------------------------------- ------ 316.1/385.0 MB 20.5 MB/s eta 0:00:04\n",
            "   -------------------------------- ------ 317.1/385.0 MB 23.4 MB/s eta 0:00:03\n",
            "   -------------------------------- ------ 318.2/385.0 MB 22.6 MB/s eta 0:00:03\n",
            "   -------------------------------- ------ 319.2/385.0 MB 22.6 MB/s eta 0:00:03\n",
            "   -------------------------------- ------ 320.1/385.0 MB 22.6 MB/s eta 0:00:03\n",
            "   -------------------------------- ------ 321.0/385.0 MB 22.6 MB/s eta 0:00:03\n",
            "   -------------------------------- ------ 321.8/385.0 MB 21.8 MB/s eta 0:00:03\n",
            "   -------------------------------- ------ 322.8/385.0 MB 22.6 MB/s eta 0:00:03\n",
            "   -------------------------------- ------ 323.8/385.0 MB 21.1 MB/s eta 0:00:03\n",
            "   -------------------------------- ------ 324.9/385.0 MB 21.1 MB/s eta 0:00:03\n",
            "   -------------------------------- ------ 325.7/385.0 MB 21.1 MB/s eta 0:00:03\n",
            "   --------------------------------- ----- 326.6/385.0 MB 20.5 MB/s eta 0:00:03\n",
            "   --------------------------------- ----- 326.7/385.0 MB 18.7 MB/s eta 0:00:04\n",
            "   --------------------------------- ----- 327.6/385.0 MB 19.3 MB/s eta 0:00:03\n",
            "   --------------------------------- ----- 328.4/385.0 MB 18.7 MB/s eta 0:00:04\n",
            "   --------------------------------- ----- 329.4/385.0 MB 18.2 MB/s eta 0:00:04\n",
            "   --------------------------------- ----- 330.7/385.0 MB 18.7 MB/s eta 0:00:03\n",
            "   --------------------------------- ----- 330.9/385.0 MB 18.7 MB/s eta 0:00:03\n",
            "   --------------------------------- ----- 330.9/385.0 MB 18.7 MB/s eta 0:00:03\n",
            "   --------------------------------- ----- 331.0/385.0 MB 15.2 MB/s eta 0:00:04\n",
            "   --------------------------------- ----- 331.7/385.0 MB 14.6 MB/s eta 0:00:04\n",
            "   --------------------------------- ----- 332.3/385.0 MB 14.5 MB/s eta 0:00:04\n",
            "   --------------------------------- ----- 333.2/385.0 MB 14.9 MB/s eta 0:00:04\n",
            "   --------------------------------- ----- 333.9/385.0 MB 14.6 MB/s eta 0:00:04\n",
            "   --------------------------------- ----- 334.7/385.0 MB 14.2 MB/s eta 0:00:04\n",
            "   --------------------------------- ----- 335.5/385.0 MB 14.6 MB/s eta 0:00:04\n",
            "   ---------------------------------- ---- 336.0/385.0 MB 14.2 MB/s eta 0:00:04\n",
            "   ---------------------------------- ---- 337.0/385.0 MB 15.6 MB/s eta 0:00:04\n",
            "   ---------------------------------- ---- 337.7/385.0 MB 14.9 MB/s eta 0:00:04\n",
            "   ---------------------------------- ---- 338.6/385.0 MB 14.6 MB/s eta 0:00:04\n",
            "   ---------------------------------- ---- 339.3/385.0 MB 14.9 MB/s eta 0:00:04\n",
            "   ---------------------------------- ---- 340.0/385.0 MB 14.6 MB/s eta 0:00:04\n",
            "   ---------------------------------- ---- 341.2/385.0 MB 16.4 MB/s eta 0:00:03\n",
            "   ---------------------------------- ---- 341.8/385.0 MB 17.7 MB/s eta 0:00:03\n",
            "   ---------------------------------- ---- 342.8/385.0 MB 17.7 MB/s eta 0:00:03\n",
            "   ---------------------------------- ---- 343.5/385.0 MB 17.2 MB/s eta 0:00:03\n",
            "   ---------------------------------- ---- 344.1/385.0 MB 16.8 MB/s eta 0:00:03\n",
            "   ---------------------------------- ---- 345.1/385.0 MB 17.7 MB/s eta 0:00:03\n",
            "   ----------------------------------- --- 345.9/385.0 MB 17.7 MB/s eta 0:00:03\n",
            "   ----------------------------------- --- 346.9/385.0 MB 17.7 MB/s eta 0:00:03\n",
            "   ----------------------------------- --- 347.7/385.0 MB 17.7 MB/s eta 0:00:03\n",
            "   ----------------------------------- --- 348.5/385.0 MB 17.7 MB/s eta 0:00:03\n",
            "   ----------------------------------- --- 349.4/385.0 MB 18.2 MB/s eta 0:00:02\n",
            "   ----------------------------------- --- 350.1/385.0 MB 18.2 MB/s eta 0:00:02\n",
            "   ----------------------------------- --- 350.9/385.0 MB 18.2 MB/s eta 0:00:02\n",
            "   ----------------------------------- --- 350.9/385.0 MB 18.2 MB/s eta 0:00:02\n",
            "   ----------------------------------- --- 351.0/385.0 MB 15.6 MB/s eta 0:00:03\n",
            "   ----------------------------------- --- 351.4/385.0 MB 15.2 MB/s eta 0:00:03\n",
            "   ----------------------------------- --- 352.1/385.0 MB 14.9 MB/s eta 0:00:03\n",
            "   ----------------------------------- --- 353.0/385.0 MB 15.2 MB/s eta 0:00:03\n",
            "   ----------------------------------- --- 353.6/385.0 MB 14.9 MB/s eta 0:00:03\n",
            "   ----------------------------------- --- 354.2/385.0 MB 14.9 MB/s eta 0:00:03\n",
            "   ----------------------------------- --- 354.8/385.0 MB 14.9 MB/s eta 0:00:03\n",
            "   ------------------------------------ -- 355.6/385.0 MB 14.6 MB/s eta 0:00:03\n",
            "   ------------------------------------ -- 356.4/385.0 MB 14.9 MB/s eta 0:00:02\n",
            "   ------------------------------------ -- 357.0/385.0 MB 14.6 MB/s eta 0:00:02\n",
            "   ------------------------------------ -- 357.6/385.0 MB 14.2 MB/s eta 0:00:02\n",
            "   ------------------------------------ -- 358.3/385.0 MB 14.6 MB/s eta 0:00:02\n",
            "   ------------------------------------ -- 359.0/385.0 MB 13.9 MB/s eta 0:00:02\n",
            "   ------------------------------------ -- 359.7/385.0 MB 13.9 MB/s eta 0:00:02\n",
            "   ------------------------------------ -- 360.4/385.0 MB 13.9 MB/s eta 0:00:02\n",
            "   ------------------------------------ -- 361.1/385.0 MB 13.6 MB/s eta 0:00:02\n",
            "   ------------------------------------ -- 362.0/385.0 MB 16.0 MB/s eta 0:00:02\n",
            "   ------------------------------------ -- 362.6/385.0 MB 16.0 MB/s eta 0:00:02\n",
            "   ------------------------------------ -- 363.4/385.0 MB 15.6 MB/s eta 0:00:02\n",
            "   ------------------------------------ -- 364.2/385.0 MB 15.2 MB/s eta 0:00:02\n",
            "   ------------------------------------ -- 364.9/385.0 MB 16.0 MB/s eta 0:00:02\n",
            "   ------------------------------------- - 365.4/385.0 MB 15.6 MB/s eta 0:00:02\n",
            "   ------------------------------------- - 366.1/385.0 MB 15.6 MB/s eta 0:00:02\n",
            "   ------------------------------------- - 366.7/385.0 MB 15.6 MB/s eta 0:00:02\n",
            "   ------------------------------------- - 367.5/385.0 MB 15.2 MB/s eta 0:00:02\n",
            "   ------------------------------------- - 367.7/385.0 MB 15.6 MB/s eta 0:00:02\n",
            "   ------------------------------------- - 367.7/385.0 MB 15.6 MB/s eta 0:00:02\n",
            "   ------------------------------------- - 367.7/385.0 MB 15.6 MB/s eta 0:00:02\n",
            "   ------------------------------------- - 367.7/385.0 MB 15.6 MB/s eta 0:00:02\n",
            "   ------------------------------------- - 367.7/385.0 MB 15.6 MB/s eta 0:00:02\n",
            "   ------------------------------------- - 367.7/385.0 MB 15.6 MB/s eta 0:00:02\n",
            "   ------------------------------------- - 367.7/385.0 MB 15.6 MB/s eta 0:00:02\n",
            "   ------------------------------------- - 367.7/385.0 MB 10.1 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 368.1/385.0 MB 9.6 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 368.7/385.0 MB 9.6 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 369.4/385.0 MB 9.6 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 370.1/385.0 MB 9.6 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 370.7/385.0 MB 9.6 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 371.4/385.0 MB 9.8 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 372.0/385.0 MB 9.6 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 372.7/385.0 MB 9.5 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 373.4/385.0 MB 9.6 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 374.4/385.0 MB 9.8 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 375.1/385.0 MB 9.8 MB/s eta 0:00:02\n",
            "   ---------------------------------------  376.0/385.0 MB 9.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  376.8/385.0 MB 9.9 MB/s eta 0:00:01\n",
            "   --------------------------------------  377.8/385.0 MB 10.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  378.4/385.0 MB 16.8 MB/s eta 0:00:01\n",
            "   --------------------------------------  379.3/385.0 MB 16.8 MB/s eta 0:00:01\n",
            "   --------------------------------------  380.5/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  381.0/385.0 MB 18.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  381.1/385.0 MB 16.0 MB/s eta 0:00:01\n",
            "   --------------------------------------  382.2/385.0 MB 16.8 MB/s eta 0:00:01\n",
            "   --------------------------------------  382.9/385.0 MB 17.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  384.0/385.0 MB 17.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   --------------------------------------  385.0/385.0 MB 18.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 385.0/385.0 MB 2.5 MB/s eta 0:00:00\n",
            "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
            "Downloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
            "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
            "   ------- -------------------------------- 1.0/5.5 MB 31.7 MB/s eta 0:00:01\n",
            "   ------------- -------------------------- 1.9/5.5 MB 23.9 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 2.9/5.5 MB 26.6 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 4.3/5.5 MB 24.8 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 5.2/5.5 MB 23.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------  5.5/5.5 MB 23.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------  5.5/5.5 MB 23.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 5.5/5.5 MB 16.7 MB/s eta 0:00:00\n",
            "Installing collected packages: flatbuffers, threadpoolctl, tensorboard, scikit-learn, keras, tensorflow-intel, tensorflow\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 23.5.26\n",
            "    Uninstalling flatbuffers-23.5.26:\n",
            "      Successfully uninstalled flatbuffers-23.5.26\n",
            "  Attempting uninstall: threadpoolctl\n",
            "    Found existing installation: threadpoolctl 2.2.0\n",
            "    Uninstalling threadpoolctl-2.2.0:\n",
            "      Successfully uninstalled threadpoolctl-2.2.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.16.2\n",
            "    Uninstalling tensorboard-2.16.2:\n",
            "      Successfully uninstalled tensorboard-2.16.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.3.0\n",
            "    Uninstalling scikit-learn-1.3.0:\n",
            "      Successfully uninstalled scikit-learn-1.3.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.1.1\n",
            "    Uninstalling keras-3.1.1:\n",
            "      Successfully uninstalled keras-3.1.1\n",
            "  Attempting uninstall: tensorflow-intel\n",
            "    Found existing installation: tensorflow-intel 2.16.1\n",
            "    Uninstalling tensorflow-intel-2.16.1:\n",
            "      Successfully uninstalled tensorflow-intel-2.16.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.16.1\n",
            "    Uninstalling tensorflow-2.16.1:\n",
            "      Successfully uninstalled tensorflow-2.16.1\n",
            "Successfully installed flatbuffers-24.3.25 keras-3.4.1 scikit-learn-1.5.2 tensorboard-2.17.1 tensorflow-2.17.0 tensorflow-intel-2.17.0 threadpoolctl-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.17.0 keras==3.4.1 scikit-learn==1.5.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PfGqaw6nkkyL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding, LSTM, Bidirectional, Dense, Concatenate\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRgjQ8Azk_vq",
        "outputId": "eaef950b-ff23-4035-e6d6-adb4bd75f11f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'pip' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'pip' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'pip' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install xlrd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TQTsed2Il5hA"
      },
      "outputs": [],
      "source": [
        "import pandas  as pd\n",
        "data = pd.read_excel(r\"C:\\Users\\Dell\\Documents\\Capstone\\dict.xlsx\")\n",
        "\n",
        "\n",
        "sanskrit_words = data['Sanskrit'].astype(str)\n",
        "english_words = data['English'].astype(str)\n",
        "\n",
        "# Hyperparameters\n",
        "embedding_dim = 128\n",
        "units = 256\n",
        "max_length_sanskrit = 2  # Word-level data, so length = 1\n",
        "max_length_english = 2  # Word-level data, so length = 1\n",
        "\n",
        "# Tokenizer for Sanskrit\n",
        "tokenizer_sanskrit = Tokenizer(filters='', lower=False)\n",
        "tokenizer_sanskrit.fit_on_texts(sanskrit_words)\n",
        "sanskrit_sequences = tokenizer_sanskrit.texts_to_sequences(sanskrit_words)\n",
        "sanskrit_padded = pad_sequences(sanskrit_sequences, maxlen=max_length_sanskrit, padding='post')\n",
        "\n",
        "# Tokenizer for English\n",
        "tokenizer_english = Tokenizer(filters='', lower=False)\n",
        "tokenizer_english.fit_on_texts(english_words)\n",
        "english_sequences = tokenizer_english.texts_to_sequences(english_words)\n",
        "english_padded = pad_sequences(english_sequences, maxlen=max_length_english, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2hUFQqaEmPot"
      },
      "outputs": [],
      "source": [
        "# Vocabulary sizes\n",
        "vocab_size_sanskrit = len(tokenizer_sanskrit.word_index) + 1\n",
        "vocab_size_english = len(tokenizer_english.word_index) + 1\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(sanskrit_padded, english_padded, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CmdAFJAam6xE"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Exception encountered when calling Bidirectional.call().\n\n\u001b[1mcan only concatenate list (not \"tuple\") to list\u001b[0m\n\nArguments received by Bidirectional.call():\n  • args=('<KerasTensor shape=(None, 2, 128), dtype=float32, sparse=False, name=keras_tensor_5>',)\n  • kwargs={'mask': 'None'}",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m encoder_biLSTM \u001b[38;5;241m=\u001b[39m Bidirectional(LSTM(units, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, return_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Forward and backward states\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m encoder_outputs, forward_h, forward_c, backward_h, backward_c \u001b[38;5;241m=\u001b[39m encoder_biLSTM(encoder_embedding)\n\u001b[0;32m      8\u001b[0m state_h \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConcatenate()([forward_h, backward_h])  \u001b[38;5;66;03m# Concatenate forward and backward hidden states\u001b[39;00m\n\u001b[0;32m      9\u001b[0m state_c \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConcatenate()([forward_c, backward_c])  \u001b[38;5;66;03m# Concatenate forward and backward cell states\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:190\u001b[0m, in \u001b[0;36mBidirectional.compute_output_shape\u001b[1;34m(self, sequences_shape, initial_state_shape)\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerge_mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m output_shape \u001b[38;5;241m+\u001b[39m state_shape \u001b[38;5;241m+\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(state_shape)\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [output_shape] \u001b[38;5;241m+\u001b[39m state_shape \u001b[38;5;241m+\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(state_shape)\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output_shape\n",
            "\u001b[1;31mTypeError\u001b[0m: Exception encountered when calling Bidirectional.call().\n\n\u001b[1mcan only concatenate list (not \"tuple\") to list\u001b[0m\n\nArguments received by Bidirectional.call():\n  • args=('<KerasTensor shape=(None, 2, 128), dtype=float32, sparse=False, name=keras_tensor_5>',)\n  • kwargs={'mask': 'None'}"
          ]
        }
      ],
      "source": [
        "# Encoder (Sanskrit)\n",
        "encoder_inputs = Input(shape=(max_length_sanskrit,))\n",
        "encoder_embedding = Embedding(input_dim=vocab_size_sanskrit, output_dim=embedding_dim)(encoder_inputs)\n",
        "encoder_biLSTM = Bidirectional(LSTM(units, return_sequences=False, return_state=True))\n",
        "\n",
        "# Forward and backward states\n",
        "encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder_biLSTM(encoder_embedding)\n",
        "state_h = Concatenate()([forward_h, backward_h])  # Concatenate forward and backward hidden states\n",
        "state_c = Concatenate()([forward_c, backward_c])  # Concatenate forward and backward cell states\n",
        "\n",
        "# Decoder (English)\n",
        "decoder_inputs = Input(shape=(max_length_english,))\n",
        "decoder_embedding = Embedding(input_dim=vocab_size_english, output_dim=embedding_dim)(decoder_inputs)\n",
        "decoder_lstm = LSTM(units * 2, return_sequences=True, return_state=True)\n",
        "\n",
        "# Using the encoder's states as initial states for the decoder\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=[state_h, state_c])\n",
        "decoder_dense = Dense(vocab_size_english, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "i48GDr3qnCuT",
        "outputId": "1a060d7b-51ca-4087-b676-a434df7126b2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">161,920</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ bidirectional_1           │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">788,480</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     │                │                        │\n",
              "│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │                        │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                  │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">150,400</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>], │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>], │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,312,768</span> │ embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]                  │                │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1175</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">602,775</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m161,920\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ bidirectional_1           │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,   │        \u001b[38;5;34m788,480\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)           │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     │                │                        │\n",
              "│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │                        │\n",
              "│                           │ \u001b[38;5;34m256\u001b[0m)]                  │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m150,400\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ bidirectional_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m], │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ bidirectional_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m3\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ bidirectional_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m], │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ bidirectional_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m4\u001b[0m]  │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)             │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m512\u001b[0m),       │      \u001b[38;5;34m1,312,768\u001b[0m │ embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │ concatenate_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │ \u001b[38;5;34m512\u001b[0m)]                  │                │ concatenate_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m1175\u001b[0m)        │        \u001b[38;5;34m602,775\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,016,343</span> (11.51 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,016,343\u001b[0m (11.51 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,016,343</span> (11.51 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,016,343\u001b[0m (11.51 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Encoder (Sanskrit)\n",
        "encoder_inputs = Input(shape=(max_length_sanskrit,))\n",
        "encoder_embedding = Embedding(input_dim=vocab_size_sanskrit, output_dim=embedding_dim)(encoder_inputs)\n",
        "encoder_biLSTM = Bidirectional(LSTM(units, return_sequences=False, return_state=True))\n",
        "\n",
        "# Forward and backward states\n",
        "encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder_biLSTM(encoder_embedding)\n",
        "state_h = Concatenate()([forward_h, backward_h])  # Concatenate forward and backward hidden states\n",
        "state_c = Concatenate()([forward_c, backward_c])  # Concatenate forward and backward cell states\n",
        "\n",
        "# Decoder (English)\n",
        "decoder_inputs = Input(shape=(max_length_english,))\n",
        "decoder_embedding = Embedding(input_dim=vocab_size_english, output_dim=embedding_dim)(decoder_inputs)\n",
        "decoder_lstm = LSTM(units * 2, return_sequences=True, return_state=True)\n",
        "\n",
        "# Using the encoder's states as initial states for the decoder\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=[state_h, state_c])\n",
        "decoder_dense = Dense(vocab_size_english, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Full model combining encoder and decoder\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n",
        "\n",
        "# Training\n",
        "\n",
        "# Shift the target English words by one for teacher forcing\n",
        "y_train_shifted = np.expand_dims(np.roll(y_train, -1, axis=1), -1)\n",
        "y_test_shifted = np.expand_dims(np.roll(y_test, -1, axis=1), -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiyhYCzfikhL",
        "outputId": "da6d255c-bf00-4530-b622-5016557b4577"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6557 - loss: 1.4070 - val_accuracy: 0.5342 - val_loss: 5.2317\n",
            "Epoch 2/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6460 - loss: 1.3972 - val_accuracy: 0.5326 - val_loss: 5.3199\n",
            "Epoch 3/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6510 - loss: 1.3792 - val_accuracy: 0.5311 - val_loss: 5.2437\n",
            "Epoch 4/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6726 - loss: 1.3470 - val_accuracy: 0.5435 - val_loss: 5.3398\n",
            "Epoch 5/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6754 - loss: 1.3259 - val_accuracy: 0.5326 - val_loss: 5.3407\n",
            "Epoch 6/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6839 - loss: 1.2644 - val_accuracy: 0.5373 - val_loss: 5.2917\n",
            "Epoch 7/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6619 - loss: 1.2894 - val_accuracy: 0.5404 - val_loss: 5.3076\n",
            "Epoch 8/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6751 - loss: 1.2832 - val_accuracy: 0.5388 - val_loss: 5.3116\n",
            "Epoch 9/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6761 - loss: 1.2882 - val_accuracy: 0.5373 - val_loss: 5.3821\n",
            "Epoch 10/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6877 - loss: 1.2323 - val_accuracy: 0.5419 - val_loss: 5.2995\n",
            "Epoch 11/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6837 - loss: 1.2162 - val_accuracy: 0.5528 - val_loss: 5.3579\n",
            "Epoch 12/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7070 - loss: 1.1751 - val_accuracy: 0.5435 - val_loss: 5.3685\n",
            "Epoch 13/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6987 - loss: 1.1999 - val_accuracy: 0.5450 - val_loss: 5.3398\n",
            "Epoch 14/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7048 - loss: 1.1436 - val_accuracy: 0.5528 - val_loss: 5.3648\n",
            "Epoch 15/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7162 - loss: 1.1320 - val_accuracy: 0.5497 - val_loss: 5.3350\n",
            "Epoch 16/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7079 - loss: 1.1244 - val_accuracy: 0.5512 - val_loss: 5.3928\n",
            "Epoch 17/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7025 - loss: 1.1363 - val_accuracy: 0.5435 - val_loss: 5.3359\n",
            "Epoch 18/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7111 - loss: 1.1287 - val_accuracy: 0.5466 - val_loss: 5.4133\n",
            "Epoch 19/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7298 - loss: 1.0524 - val_accuracy: 0.5575 - val_loss: 5.3910\n",
            "Epoch 20/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7270 - loss: 1.0518 - val_accuracy: 0.5606 - val_loss: 5.3818\n",
            "Epoch 21/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7372 - loss: 1.0211 - val_accuracy: 0.5606 - val_loss: 5.3412\n",
            "Epoch 22/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7376 - loss: 1.0159 - val_accuracy: 0.5652 - val_loss: 5.4656\n",
            "Epoch 23/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7450 - loss: 1.0020 - val_accuracy: 0.5543 - val_loss: 5.4624\n",
            "Epoch 24/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7464 - loss: 0.9858 - val_accuracy: 0.5590 - val_loss: 5.3381\n",
            "Epoch 25/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7626 - loss: 0.9527 - val_accuracy: 0.5559 - val_loss: 5.4579\n",
            "Epoch 26/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7709 - loss: 0.9506 - val_accuracy: 0.5714 - val_loss: 5.5256\n",
            "Epoch 27/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7907 - loss: 0.9042 - val_accuracy: 0.5668 - val_loss: 5.4103\n",
            "Epoch 28/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7858 - loss: 0.8995 - val_accuracy: 0.5761 - val_loss: 5.3835\n",
            "Epoch 29/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8070 - loss: 0.8827 - val_accuracy: 0.5637 - val_loss: 5.4649\n",
            "Epoch 30/30\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8051 - loss: 0.8467 - val_accuracy: 0.5683 - val_loss: 5.5007\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    [X_train, y_train],\n",
        "    y_train_shifted,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    validation_data=([X_test, y_test], y_test_shifted)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8u2sDOhinRES",
        "outputId": "2a750d57-2f2d-4e16-a48c-0968142ee7c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Accuracy: 0.00%\n",
            "Input (Sanskrit): अहम्\n",
            "Translation(English): \n",
            "\n",
            "Input (Sanskrit): माम्\n",
            "Translation(English): decide\n",
            "\n",
            "Input (Sanskrit): त्वम्\n",
            "Translation(English): \n",
            "\n",
            "Input (Sanskrit): गच्छ\n",
            "Translation(English): thunder\n",
            "\n",
            "Input (Sanskrit): अगच्छत्\n",
            "Translation(English): \n",
            "\n",
            "Input (Sanskrit): सः\n",
            "Translation(English): decide\n",
            "\n",
            "Input (Sanskrit): सा\n",
            "Translation(English): \n",
            "\n",
            "Input (Sanskrit): तत्\n",
            "Translation(English): firing\n",
            "\n",
            "Input (Sanskrit): वयम्\n",
            "Translation(English): \n",
            "\n",
            "Input (Sanskrit): ते\n",
            "Translation(English): design\n",
            "\n",
            "Input (Sanskrit): एतत्\n",
            "Translation(English): \n",
            "\n",
            "Input (Sanskrit): तत्\n",
            "Translation(English): design\n",
            "\n",
            "Input (Sanskrit): कः\n",
            "Translation(English): \n",
            "\n",
            "Input (Sanskrit): किम्\n",
            "Translation(English): bring\n",
            "\n",
            "Input (Sanskrit): कुत्र\n",
            "Translation(English): \n",
            "\n",
            "Input (Sanskrit): कदा\n",
            "Translation(English): stir\n",
            "\n",
            "Input (Sanskrit): किमर्थम्\n",
            "Translation(English): \n",
            "\n",
            "Input (Sanskrit): कथम्\n",
            "Translation(English): firing\n",
            "\n",
            "Input (Sanskrit): कतमः\n",
            "Translation(English): \n",
            "\n",
            "Input (Sanskrit): आगच्छ\n",
            "Translation(English): catalog\n",
            "\n",
            "Input (Sanskrit): उपविश\n",
            "Translation(English): \n",
            "\n",
            "Input (Sanskrit): तिष्ठ\n",
            "Translation(English): design\n",
            "\n",
            "Input (Sanskrit): वद\n",
            "Translation(English): \n",
            "\n",
            "Input (Sanskrit): शृणु\n",
            "Translation(English): blue\n",
            "\n",
            "Input (Sanskrit): अश\n",
            "Translation(English): \n",
            "\n",
            "Input (Sanskrit): पिब\n",
            "Translation(English): borrow\n",
            "\n",
            "Input (Sanskrit): स्वप\n",
            "Translation(English): \n",
            "\n",
            "Input (Sanskrit): चर\n",
            "Translation(English): design\n",
            "\n",
            "Input (Sanskrit): धाव\n",
            "Translation(English): \n",
            "\n",
            "Input (Sanskrit): सहायम् कर\n",
            "Translation(English): airplane\n",
            "\n",
            "Input (Sanskrit): कृपया\n",
            "Translation(English): \n",
            "\n",
            "Input (Sanskrit): धन्यवादः\n",
            "Translation(English): near\n",
            "\n",
            "Input (Sanskrit): क्षम्यताम्\n",
            "Translation(English): \n",
            "\n",
            "Input (Sanskrit): आम्\n",
            "Translation(English): thunder\n",
            "\n",
            "Input (Sanskrit): न\n",
            "Translation(English): \n",
            "\n",
            "Input (Sanskrit): कुरु\n",
            "Translation(English): immigration\n",
            "\n",
            "Input (Sanskrit): करोति\n",
            "Translation(English): \n",
            "\n",
            "Input (Sanskrit): कृतम्\n",
            "Translation(English): brain\n",
            "\n",
            "Input (Sanskrit): मन्ये\n",
            "Translation(English): \n",
            "\n",
            "Input (Sanskrit): चिन्तयति\n",
            "Translation(English): salvation\n",
            "\n",
            "Input (Sanskrit): चिन्तितम्\n",
            "Translation(English): \n",
            "\n",
            "Input (Sanskrit): ददातु\n",
            "Translation(English): campaign\n",
            "\n",
            "Input (Sanskrit): ददाति\n",
            "Translation(English): \n",
            "\n",
            "Input (Sanskrit): दत्तम्\n",
            "Translation(English): thunder\n",
            "\n",
            "Input (Sanskrit): पठ\n",
            "Translation(English): \n",
            "\n",
            "Input (Sanskrit): पठति\n",
            "Translation(English): design\n",
            "\n",
            "Input (Sanskrit): पठितम्\n",
            "Translation(English): \n",
            "\n",
            "Input (Sanskrit): लिख\n",
            "Translation(English): inside\n",
            "\n",
            "Input (Sanskrit): लिखति\n",
            "Translation(English): \n",
            "\n",
            "Input (Sanskrit): लिखितम्\n",
            "Translation(English): likewise\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluation\n",
        "# Predict on the test data\n",
        "predictions = model.predict([X_test, y_test])\n",
        "\n",
        "# Convert predictions back to words\n",
        "predicted_words = np.argmax(predictions, axis=-1)\n",
        "\n",
        "# Convert indices back to words\n",
        "y_test_flat = y_test.flatten()\n",
        "predicted_flat = predicted_words.flatten()\n",
        "\n",
        "# Inverse map from index to word\n",
        "index_to_word_english = {index: word for word, index in tokenizer_english.word_index.items()}\n",
        "\n",
        "# Convert predictions to words\n",
        "y_test_words = [index_to_word_english.get(index, '') for index in y_test_flat]\n",
        "predicted_words = [index_to_word_english.get(index, '') for index in predicted_flat]\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test_flat, predicted_flat)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Display some test cases with their predictions\n",
        "for i in range(50):\n",
        "    print(f\"Input (Sanskrit): {sanskrit_words[i]}\")\n",
        "    print(f\"Translation(English): {predicted_words[i]}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbG1eKeynbO5",
        "outputId": "63efc513-97a3-4afd-e0ec-e256de606649"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model_word = model.save(\"model_word.h5\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEOawFIOomqq",
        "outputId": "7f7e2f2d-4cc1-41ef-cc49-4c2d5b6c0d56"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.7794 - loss: 0.8846 - val_accuracy: 0.5652 - val_loss: 5.3047\n",
            "Epoch 2/5\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7830 - loss: 0.8684 - val_accuracy: 0.5714 - val_loss: 5.4240\n",
            "Epoch 3/5\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8198 - loss: 0.8176 - val_accuracy: 0.5792 - val_loss: 5.4367\n",
            "Epoch 4/5\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8232 - loss: 0.7789 - val_accuracy: 0.5807 - val_loss: 5.5125\n",
            "Epoch 5/5\n",
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8306 - loss: 0.7559 - val_accuracy: 0.5776 - val_loss: 5.5303\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "loaded_model = load_model('model_word.h5')\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(\n",
        "    [X_train, y_train],\n",
        "    y_train_shifted,\n",
        "    epochs=5,\n",
        "    batch_size=32,\n",
        "    validation_data=([X_test, y_test], y_test_shifted)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "ShUbeNIarBKg",
        "outputId": "451c2856-54fc-4f37-a685-15a93da8e43b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Invalid dtype: ellipsis",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-c60a545bdc2e>\u001b[0m in \u001b[0;36m<cell line: 52>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0minput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m  \u001b[0;31m# Dimensionality of the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0moutput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m  \u001b[0;31m# Number of possible actions (e.g., vocabulary size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mpretrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# Initialize the agent with the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-c60a545bdc2e>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(input_dim, output_dim)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Output probabilities for actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer, rebuild)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_input_shape_arg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInputLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_shape_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# If we are passed a Keras tensor created by keras.Input(), we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, shape, batch_size, dtype, sparse, batch_shape, input_tensor, optional, name, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandardize_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/variables.py\u001b[0m in \u001b[0;36mstandardize_shape\u001b[0;34m(shape)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0;31m# JAX2TF tracing uses JAX-native dimension expressions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_int_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             raise ValueError(\n\u001b[1;32m    551\u001b[0m                 \u001b[0;34mf\"Cannot convert '{shape}' to a shape. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/variables.py\u001b[0m in \u001b[0;36mis_int_dtype\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mkeras_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"keras.backend.is_int_dtype\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_int_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"int\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"uint\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/variables.py\u001b[0m in \u001b[0;36mstandardize_dtype\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALLOWED_DTYPES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Invalid dtype: {dtype}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid dtype: ellipsis"
          ]
        }
      ],
      "source": [
        "# import numpy as np\n",
        "# import keras\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense\n",
        "# from keras.optimizers import Adam\n",
        "\n",
        "# class HumanFeedbackAgent:\n",
        "#     def __init__(self, model):\n",
        "#         self.model = model  # Pre-trained model\n",
        "#         self.learning_rate = 0.001\n",
        "#         self.discount_factor = 0.99  # Future reward discount\n",
        "#         self.optimizer = Adam(learning_rate=self.learning_rate)\n",
        "\n",
        "#     # Function to calculate rewards based on human feedback\n",
        "#     def get_reward(self, human_feedback):\n",
        "#         if human_feedback == 'positive':\n",
        "#             return 1.0\n",
        "#         elif human_feedback == 'negative':\n",
        "#             return -1.0\n",
        "#         else:\n",
        "#             return 0.0\n",
        "\n",
        "#     # Update policy based on feedback\n",
        "#     def train(self, state, action, reward):\n",
        "#         with tf.GradientTape() as tape:\n",
        "#             # Forward pass through the model to get predictions\n",
        "#             prediction = self.model(state)\n",
        "\n",
        "#             # Loss function (we'll use policy gradient with rewards)\n",
        "#             loss = -reward * tf.math.log(prediction[action])\n",
        "\n",
        "#         # Compute gradients and update the model weights\n",
        "#         gradients = tape.gradient(loss, self.model.trainable_variables)\n",
        "#         self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
        "\n",
        "#     # Predict the best action (e.g., translation output)\n",
        "#     def predict(self, state):\n",
        "#         action_probs = self.model(state)\n",
        "#         return np.argmax(action_probs, axis=1)\n",
        "\n",
        "# # Define the model architecture for RL agent\n",
        "# def create_model(input_dim, output_dim):\n",
        "#     model = Sequential()\n",
        "#     model.add(Dense(128, input_dim=input_dim, activation='relu'))\n",
        "#     model.add(Dense(64, activation='relu'))\n",
        "#     model.add(Dense(output_dim, activation='softmax'))  # Output probabilities for actions\n",
        "#     return model\n",
        "\n",
        "# # Initialize the model\n",
        "# input_dim = ...  # Dimensionality of the input\n",
        "# output_dim = ...  # Number of possible actions (e.g., vocabulary size)\n",
        "# pretrained_model = create_model(input_dim, output_dim)\n",
        "\n",
        "# # Initialize the agent with the model\n",
        "# agent = HumanFeedbackAgent(pretrained_model)\n",
        "\n",
        "# # Example state (input data for prediction)\n",
        "# state = np.array([...])  # Input data (e.g., tokenized text)\n",
        "\n",
        "# # Agent predicts output\n",
        "# predicted_action = agent.predict(state)\n",
        "\n",
        "# # Simulate human feedback (in practice, you'd collect this from a user)\n",
        "# human_feedback = 'positive'  # Can be 'positive' or 'negative'\n",
        "\n",
        "# # Convert feedback to a reward\n",
        "# reward = agent.get_reward(human_feedback)\n",
        "\n",
        "# # Train agent based on feedback\n",
        "# agent.train(state, predicted_action, reward)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "axF8_OFHvMH6",
        "outputId": "4d1e74dd-80a7-4c94-fe34-cf04a4d75873"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Invalid dtype: ellipsis",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-c03efe23eee1>\u001b[0m in \u001b[0;36m<cell line: 57>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0minput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m  \u001b[0;31m# Dimensionality of the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0moutput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m  \u001b[0;31m# Number of possible actions (e.g., vocabulary size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mpretrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# Initialize the agent with the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-c03efe23eee1>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(input_dim, output_dim)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Output probabilities for actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer, rebuild)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_input_shape_arg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInputLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_shape_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# If we are passed a Keras tensor created by keras.Input(), we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, shape, batch_size, dtype, sparse, batch_shape, input_tensor, optional, name, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandardize_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/variables.py\u001b[0m in \u001b[0;36mstandardize_shape\u001b[0;34m(shape)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0;31m# JAX2TF tracing uses JAX-native dimension expressions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_int_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             raise ValueError(\n\u001b[1;32m    551\u001b[0m                 \u001b[0;34mf\"Cannot convert '{shape}' to a shape. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/variables.py\u001b[0m in \u001b[0;36mis_int_dtype\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mkeras_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"keras.backend.is_int_dtype\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_int_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"int\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"uint\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/common/variables.py\u001b[0m in \u001b[0;36mstandardize_dtype\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALLOWED_DTYPES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Invalid dtype: {dtype}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid dtype: ellipsis"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "\n",
        "input_dim = 100 # Replace with the actual dimensionality of your input\n",
        "output_dim = 1000 # Replace with the actual number of possible actions (e.g., vocabulary size)\n",
        "pretrained_model = create_model(input_dim, output_dim)\n",
        "\n",
        "class HumanFeedbackAgent:\n",
        "    def __init__(self, model):\n",
        "        self.model = model  # Pre-trained model\n",
        "        self.learning_rate = 0.001\n",
        "        self.discount_factor = 0.99  # Future reward discount\n",
        "        self.optimizer = Adam(learning_rate=self.learning_rate)\n",
        "\n",
        "    # Function to calculate rewards based on human feedback\n",
        "    def get_reward(self, human_feedback):\n",
        "        if human_feedback == 'positive':\n",
        "            return 1.0\n",
        "        elif human_feedback == 'negative':\n",
        "            return -1.0\n",
        "        else:\n",
        "            return 0.0\n",
        "\n",
        "    # Update policy based on feedback\n",
        "    def train(self, state, action, reward):\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass through the model to get predictions\n",
        "            prediction = self.model(state)\n",
        "\n",
        "            # Loss function (we'll use policy gradient with rewards)\n",
        "            loss = -reward * tf.math.log(prediction[action])\n",
        "\n",
        "        # Compute gradients and update the model weights\n",
        "        gradients = tape.gradient(loss, self.model.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
        "\n",
        "    # Predict the best action (e.g., translation output)\n",
        "    def predict(self, state):\n",
        "        action_probs = self.model(state)\n",
        "        return np.argmax(action_probs, axis=1)\n",
        "\n",
        "# Define the model architecture for RL agent\n",
        "def create_model(input_dim, output_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, input_dim=input_dim, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(output_dim, activation='softmax'))  # Output probabilities for actions\n",
        "    return model\n",
        "\n",
        "# Initialize the model\n",
        "input_dim = ...  # Dimensionality of the input\n",
        "output_dim = ...  # Number of possible actions (e.g., vocabulary size)\n",
        "pretrained_model = create_model(input_dim, output_dim)\n",
        "\n",
        "# Initialize the agent with the model\n",
        "agent = HumanFeedbackAgent(pretrained_model)\n",
        "\n",
        "# Example state (input data for prediction)\n",
        "state = np.array([...])  # Input data (e.g., tokenized text)\n",
        "\n",
        "# Agent predicts output\n",
        "predicted_action = agent.predict(state)\n",
        "\n",
        "# Simulate human feedback (in practice, you'd collect this from a user)\n",
        "human_feedback = 'positive'  # Can be 'positive' or 'negative'\n",
        "\n",
        "# Convert feedback to a reward\n",
        "reward = agent.get_reward(human_feedback)\n",
        "\n",
        "# Train agent based on feedback\n",
        "agent.train(state, predicted_action, reward)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmya2kYxrb5O"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
